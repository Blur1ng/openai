
================================================================================
–§–ê–ô–õ: Dockerfile
================================================================================

# –ë–∞–∑–æ–≤—ã–π –æ–±—Ä–∞–∑ Python
FROM python:3.10

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
WORKDIR /app

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Python
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
COPY requirements.txt /app/

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
RUN pip install --no-cache-dir -r requirements.txt

# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
COPY . /app/

# –£–∫–∞–∑–∞—Ç—å –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à—É –∫–æ–º–∞–Ω–¥—É)
CMD ["make", "run"]

================================================================================
–§–ê–ô–õ: LICENSE
================================================================================

Copyright ¬© 2024 –ö–∏—Ä–∏–ª–ª –•–æ—Ä—å–∫–æ–≤

–ù–∞—Å—Ç–æ—è—â–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è (–¥–∞–ª–µ–µ ‚Äì ¬´–õ–∏—Ü–µ–Ω–∑–∏—è¬ª) –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –ö–∏—Ä–∏–ª–ª–æ–º –•–æ—Ä—å–∫–æ–≤—ã–º (–¥–∞–ª–µ–µ ‚Äì ¬´–í–ª–∞–¥–µ–ª–µ—Ü¬ª), –∏ –≤—Å–µ—Ö —Å–æ–ø—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.

1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è

1.1. –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ: –õ—é–±—ã–µ –æ–±—ä–µ–∫—Ç–Ω—ã–µ –∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–¥—ã, –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, —Å–∫—Ä–∏–ø—Ç—ã, –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–µ —Ñ–∞–π–ª—ã, –∞ —Ç–∞–∫–∂–µ –ª—é–±–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è, —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞, —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ–º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏, –∏–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏/–∏–ª–∏ —Ä–µ—Å—É—Ä—Å—ã, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–µ –í–ª–∞–¥–µ–ª—å—Ü–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–≤–∞–µ–º—ã–µ –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ.

1.2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –õ—é–±–æ–µ –ª–∏—Ü–æ, —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ –∏–ª–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–ª—É—á–∏–ª–∞ –¥–æ—Å—Ç—É–ø –∫ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º—É –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ –Ω–∞ —É—Å–ª–æ–≤–∏—è—Ö –Ω–∞—Å—Ç–æ—è—â–µ–π –õ–∏—Ü–µ–Ω–∑–∏–∏.

1.3. –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –õ—é–±–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, –ø—Ä—è–º–æ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª–∏, –≤–∫–ª—é—á–∞—è, –Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è—Å—å: –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –≤ –ø–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã, –ø—Ä–æ–¥–∞–∂—É, sublic–µ–Ω–∑–∏–æ–Ω–Ω—É—é –ø–µ—Ä–µ–¥–∞—á—É, —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –≤ —Å–æ—Å—Ç–∞–≤–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤, –æ–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è.

1.4. –õ–∏—á–Ω–æ–µ –∏ –Ω–µ–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, –Ω–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª–∏, –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ–º–æ–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º –ª–∏—Ü–æ–º –¥–ª—è –ª–∏—á–Ω—ã—Ö —Ü–µ–ª–µ–π, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è, –Ω–µ –∫–æ–ø–∏—Ä—É–µ—Ç—Å—è –∏ –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç—Å—è –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π.

2. –ü—Ä–∞–≤–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∞–≤—Ç–æ—Ä—Å–∫–∏–µ –ø—Ä–∞–≤–∞

2.1. –í—Å–µ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∞ –Ω–∞ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ, –≤–∫–ª—é—á–∞—è –∞–≤—Ç–æ—Ä—Å–∫–∏–µ –ø—Ä–∞–≤–∞, —Ç–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞–∫–∏ –∏ –∏–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –í–ª–∞–¥–µ–ª—å—Ü—É.

2.2. –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∑–∞—â–∏—â–µ–Ω–æ –Ω–æ—Ä–º–∞–º–∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –∏ –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –æ–± –∞–≤—Ç–æ—Ä—Å–∫–æ–º –ø—Ä–∞–≤–µ –∏ —Å–º–µ–∂–Ω—ã—Ö –ø—Ä–∞–≤–∞—Ö, –∞ —Ç–∞–∫–∂–µ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–º–µ–Ω–∏–º—ã–º–∏ –∑–∞–∫–æ–Ω–∞–º–∏ –∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏.

2.3. –õ–∏—Ü–µ–Ω–∑–∏—è –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∫–∞–∫–∏—Ö-–ª–∏–±–æ –ø—Ä–∞–≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∏–ª–∏ –∏–Ω—ã—Ö –ø—Ä–∞–≤ –Ω–∞ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ, –∫—Ä–æ–º–µ –ø—Ä—è–º–æ –æ–≥–æ–≤–æ—Ä–µ–Ω–Ω—ã—Ö –≤ –Ω–∞—Å—Ç–æ—è—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ.

3. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º–∞—è –õ–∏—Ü–µ–Ω–∑–∏—è

3.1. –í–ª–∞–¥–µ–ª–µ—Ü –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—É—é, –Ω–µ–ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—É—é, –Ω–µ–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—É—é –ª–∏—Ü–µ–Ω–∑–∏—é –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –¥–ª—è –ª–∏—á–Ω—ã—Ö, –Ω–µ–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö —Ü–µ–ª–µ–π –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ —Å–æ–±–ª—é–¥–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–π –Ω–∞—Å—Ç–æ—è—â–µ–π –õ–∏—Ü–µ–Ω–∑–∏–∏.

3.2. –õ—é–±–æ–µ –∏–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ, –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω–æ–µ —è–≤–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –Ω–∞—Å—Ç–æ—è—â–µ–π –õ–∏—Ü–µ–Ω–∑–∏–µ–π, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –í–ª–∞–¥–µ–ª—å—Ü–∞.

4. –ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è

4.1. –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≤–ø—Ä–∞–≤–µ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å, —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å, –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å, –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ç—Ä–µ—Ç—å–∏–º –ª–∏—Ü–∞–º –∏–ª–∏ –∏–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –¥–µ–ª–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–º –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∏–ª–∏ –µ–≥–æ —á–∞—Å—Ç–∏ –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø–∏—Å—å–º–µ–Ω–Ω–æ–≥–æ —Å–æ–≥–ª–∞—Å–∏—è –í–ª–∞–¥–µ–ª—å—Ü–∞.

4.2. –ò–∑–º–µ–Ω–µ–Ω–∏–µ: –õ—é–±–æ–µ –≤–Ω–µ—Å–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥, –æ–±—ä–µ–∫—Ç–Ω—ã–π –∫–æ–¥ –∏–ª–∏ –∏–Ω—É—é —á–∞—Å—Ç—å –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∞–¥–∞–ø—Ç–∞—Ü–∏–∏, –ø–µ—Ä–µ–≤–æ–¥—ã, –¥–µ–∫–æ–º–ø–∏–ª—è—Ü–∏—é, —Ä–µ–≤–µ—Ä—Å-–∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –∏ –∏–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞, –±–µ–∑ –ø–∏—Å—å–º–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –í–ª–∞–¥–µ–ª—å—Ü–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–æ.

4.3. –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä—è–º–æ–π –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏ –±–µ–∑ –∑–∞–∫–ª—é—á–µ–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –ª–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω–æ–≥–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è —Å –í–ª–∞–¥–µ–ª—å—Ü–µ–º —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ.

5. –£—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

5.1. –õ–∏—á–Ω–æ–µ –∏ –Ω–µ–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω—É–∂–¥, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–æ–π, –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π –∏–ª–∏ –∏–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é.

5.2. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–∞–≤–∞ –ø–µ—Ä–µ–¥–∞—á–∏: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≤–ø—Ä–∞–≤–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ç—Ä–µ—Ç—å–∏–º –ª–∏—Ü–∞–º –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∏–ª–∏ –ø—Ä–∞–≤–∞ –Ω–∞ –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–æ–µ –ø—Ä–∞–≤–æ —è–≤–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –í–ª–∞–¥–µ–ª—å—Ü–µ–º –≤ –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —Ñ–æ—Ä–º–µ.

5.3. –ù–µ–∏–∑–º–µ–Ω–Ω–æ—Å—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ –ø—Ä–∞–≤–∞—Ö: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≤–ø—Ä–∞–≤–µ —É–¥–∞–ª—è—Ç—å, –∏–∑–º–µ–Ω—è—Ç—å –∏–ª–∏ —Å–∫—Ä—ã–≤–∞—Ç—å –∫–∞–∫–∏–µ-–ª–∏–±–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤–∞—Ö, —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–∞—Ö –∏–ª–∏ –¥—Ä—É–≥–∏–µ —É–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞–Ω–∏–µ, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ—Å—è –≤ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–∏.

6. –û—Ç–∫–∞–∑ –æ—Ç –≥–∞—Ä–∞–Ω—Ç–∏–π

6.1. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª: –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª (¬´as is¬ª) –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –≥–∞—Ä–∞–Ω—Ç–∏–π, —è–≤–Ω—ã—Ö –∏–ª–∏ –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ–º—ã—Ö, –≤–∫–ª—é—á–∞—è, –Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è—Å—å –≥–∞—Ä–∞–Ω—Ç–∏—è–º–∏ —Ç–æ–≤–∞—Ä–Ω–æ–π –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏, –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Ü–µ–ª–∏, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –Ω–∞—Ä—É—à–µ–Ω–∏–π –ø—Ä–∞–≤ —Ç—Ä–µ—Ç—å–∏—Ö –ª–∏—Ü –∏ —Ç.–ø.

6.2. –†–∏—Å–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ—Å–µ—Ç —Ä–∏—Å–∫, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è —Ä–∏—Å–∫, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –µ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é, –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å—é, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–º –æ–∂–∏–¥–∞–Ω–∏—è–º –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

7. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏

7.1. –ù–∏ –ø—Ä–∏ –∫–∞–∫–∏—Ö –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞—Ö –í–ª–∞–¥–µ–ª–µ—Ü –Ω–µ –Ω–µ—Å–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –ø—Ä—è–º–æ–π, –∫–æ—Å–≤–µ–Ω–Ω—ã–π, —Å–ª—É—á–∞–π–Ω—ã–π, –æ—Å–æ–±—ã–π, —à—Ç—Ä–∞—Ñ–Ω–æ–π –∏–ª–∏ –ª—é–±–æ–π –∏–Ω–æ–π —É—â–µ—Ä–± (–≤–∫–ª—é—á–∞—è, –ø–æ–º–∏–º–æ –ø—Ä–æ—á–µ–≥–æ, —É–ø—É—â–µ–Ω–Ω—É—é –≤—ã–≥–æ–¥—É, –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –ø–æ—Ç–µ—Ä—é –¥–µ–ª–æ–≤–æ–π —Ä–µ–ø—É—Ç–∞—Ü–∏–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ –∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏ –Ω–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏), –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–π –≤ —Å–≤—è–∑–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, –¥–∞–∂–µ –µ—Å–ª–∏ –í–ª–∞–¥–µ–ª–µ—Ü –±—ã–ª —É–≤–µ–¥–æ–º–ª–µ–Ω –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ç–∞–∫–æ–≥–æ —É—â–µ—Ä–±–∞.

7.2. –ï—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –∏–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –≥–∞—Ä–∞–Ω—Ç–∏–π –∏–ª–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—à–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –±—É–¥—É—Ç –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–π —Å—Ç–µ–ø–µ–Ω–∏, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω–æ–π —Ç–∞–∫–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.

8. –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –õ–∏—Ü–µ–Ω–∑–∏–∏

8.1. –í–ª–∞–¥–µ–ª–µ—Ü –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞ —Å–æ–±–æ–π –ø—Ä–∞–≤–æ –≤–Ω–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è, –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –õ–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ –≤ –æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–º –ø–æ—Ä—è–¥–∫–µ –≤ –ª—é–±–æ–µ –≤—Ä–µ–º—è.

8.2. –û —Ç–∞–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –±—É–¥–µ—Ç —Å–æ–æ–±—â–µ–Ω–æ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —á–µ—Ä–µ–∑ —Ä–∞–∑—É–º–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞–Ω–∞–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ LICENSE –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∏–ª–∏ –æ–ø–æ–≤–µ—â–µ–Ω–∏–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º —Å–∞–π—Ç–µ).

8.3. –î–∞–ª—å–Ω–µ–π—à–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –≤–Ω–µ—Å–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –æ–∑–Ω–∞—á–∞–µ—Ç —Å–æ–≥–ª–∞—Å–∏–µ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –Ω–æ–≤—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏.

9. –ü—Ä–∏–º–µ–Ω–∏–º–æ–µ –ø—Ä–∞–≤–æ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–ø–æ—Ä–æ–≤

9.1. –ù–∞—Å—Ç–æ—è—â–∞—è –õ–∏—Ü–µ–Ω–∑–∏—è –∏ –≤—Å–µ –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ –∏–∑ –Ω–µ–µ –∏–ª–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –Ω–µ–π –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–µ–≥—É–ª–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏–º–µ–Ω–∏–º—ã–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º —Å—Ç—Ä–∞–Ω—ã, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –í–ª–∞–¥–µ–ª—å—Ü–µ–º (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–Ω–æ–µ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏).

9.2. –í—Å–µ —Å–ø–æ—Ä—ã, —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ –∏–∑ –∏–ª–∏ –≤ —Å–≤—è–∑–∏ —Å –Ω–∞—Å—Ç–æ—è—â–µ–π –õ–∏—Ü–µ–Ω–∑–∏–µ–π, –ø–æ–¥–ª–µ–∂–∞—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—é –ø—É—Ç–µ–º –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–æ–≤. –í —Å–ª—É—á–∞–µ –Ω–µ–¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Å–æ–≥–ª–∞—à–µ–Ω–∏—è —Å–ø–æ—Ä –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Å—É–¥–∞, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–∏–º–µ–Ω–∏–º—ã–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.

10. –†–∞–∑–¥–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–µ–Ω–∏–π

10.1. –ï—Å–ª–∏ –∫–∞–∫–æ–µ-–ª–∏–±–æ –∏–∑ –ø–æ–ª–æ–∂–µ–Ω–∏–π –Ω–∞—Å—Ç–æ—è—â–µ–π –õ–∏—Ü–µ–Ω–∑–∏–∏ –±—É–¥–µ—Ç –ø—Ä–∏–∑–Ω–∞–Ω–æ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º, –Ω–µ–∑–∞–∫–æ–Ω–Ω—ã–º –∏–ª–∏ –Ω–µ –ø–æ–¥–ª–µ–∂–∞—â–∏–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–º—É –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—é, —ç—Ç–æ –Ω–µ –ø–æ–≤–ª–∏—è–µ—Ç –Ω–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–π.

================================================================================
–§–ê–ô–õ: Makefile
================================================================================

ifneq ($(wildcard .env.example),)
	ENV_FILE = .env.example
endif
ifneq ($(wildcard .env.example),)
	ifeq ($(COMPOSE_PROJECT_NAME),)
		include .env.example
	endif
endif
ifneq ($(wildcard .env),)
	ENV_FILE = .env
endif
ifneq ($(wildcard .env),)
	ifeq ($(COMPOSE_PROJECT_NAME),)
		include .env
	endif
endif

export


.SILENT:
.PHONY: help
help: ## Display this help screen
	awk 'BEGIN {FS = ':.*##'; printf 'Usage:\n  make \033[36m<target>\033[0m\n'} /^[a-zA-Z_-]+:.*?##/ { printf '  \033[36m%-18s\033[0m %s\n', $$1, $$2 } /^##@/ { printf '\n\033[1m%s\033[0m\n', substr($$0, 5) }' $(MAKEFILE_LIST)


include make/run.Makefile
include make/lint.Makefile
include make/test.Makefile
include make/migration.Makefile
include make/compose.Makefile
include make/docker.Makefile

================================================================================
–§–ê–ô–õ: README.md
================================================================================

# Linux Code Pipeline

–ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å—Ö–µ–º–∞ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞ –≤ Linux —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLVM, –æ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏.
```mermaid
flowchart TD
    A["Source Code (C, C++, Rust, etc.)"]
    %% –ò—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .c, .cpp, .rs –∏ —Ç.–¥.
    A --> B["Frontend"]
    %% –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π, —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    B --> C["AST"]
    %% –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–µ –¥–µ—Ä–µ–≤–æ
    C --> D["LLVM IR"]
    %% –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ AST –≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ SSA
    D --> E["IR Optimizations"]
    %% –ò–Ω–ª–∞–π–Ω–∏–Ω–≥, –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è, —É–¥–∞–ª–µ–Ω–∏–µ –º—ë—Ä—Ç–≤–æ–≥–æ –∫–æ–¥–∞ –∏ –¥—Ä.
    E --> F["Code Generation"]
    %% –ü–æ–Ω–∏–∂–µ–Ω–∏–µ IR –¥–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Ü–µ–ª–µ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    F --> G["Assembly (.s)"]
    %% –¢–µ–∫—Å—Ç –∞—Å—Å–µ–º–±–ª–µ—Ä–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ CPU
    G --> H["Assembler"]
    %% –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—Å—Å–µ–º–±–ª–µ—Ä–∞ –≤ –æ–±—ä–µ–∫—Ç–Ω—ã–π –∫–æ–¥
    H --> I["Object File (.o)"]
    %% –°–æ–¥–µ—Ä–∂–∏—Ç –º–∞—à–∏–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Ç–∞–±–ª–∏—Ü—ã —Å–∏–º–≤–æ–ª–æ–≤
    I --> J["Linker"]
    %% –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö .o –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ –≤ –æ–¥–∏–Ω ELF
    J --> K["Executable (ELF)"]
    %% –ì–æ—Ç–æ–≤—ã–π –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª
    K --> L["Loader"]
    %% –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã –≤ –ø–∞–º—è—Ç—å
    L --> M["Dynamic Linking"]
    %% –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ (.so)
    M --> N["Process"]
    %% –ó–∞–ø—É—â–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    N --> O["System Calls"]
    %% –í—ã–∑–æ–≤—ã —è–¥—Ä–∞ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ä–µ—Å—É—Ä—Å–∞–º (—Ñ–∞–π–ª—ã, —Å–µ—Ç—å –∏ —Ç.–¥.)
    O --> P["Kernel Space"]
    %% –Ø–¥—Ä–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º
    P --> Q["Hardware"]
    %% –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –∂–µ–ª–µ–∑–∞
```

## –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–∞–ø–æ–≤

1. **Source Code (–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥)**

   * –¢–µ–∫—Å—Ç –ø—Ä–æ–≥—Ä–∞–º–º—ã, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –Ω–∞ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–º —è–∑—ã–∫–µ (C, C++, Rust –∏ –¥—Ä.).
   * –•—Ä–∞–Ω–∏—Ç—Å—è –≤ —Ñ–∞–π–ª–∞—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ `.c`, `.cpp`, `.rs`.

2. **Frontend**

   * –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è), —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ø–∞—Ä—Å–∏–Ω–≥) –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑.
   * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞, —Ç–∏–ø–æ–≤, –æ–±–ª–∞—Å—Ç–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏.

3. **AST (Abstract Syntax Tree)**

   * –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–µ –¥–µ—Ä–µ–≤–æ, –æ—Ç—Ä–∞–∂–∞—é—â–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–≥—Ä–∞–º–º—ã.

4. **LLVM IR**

   * –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SSA, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –æ—Ç —è–∑—ã–∫–∞ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.

5. **IR Optimizations**

   * –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: –∏–Ω–ª–∞–π–Ω–∏–Ω–≥, —É–¥–∞–ª–µ–Ω–∏–µ –º—ë—Ä—Ç–≤–æ–≥–æ –∫–æ–¥–∞, –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω–æ–µ —Å–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ, –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.

6. **Code Generation**

   * –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è IR –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å —É—á—ë—Ç–æ–º –µ—ë –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π.

7. **Assembly (.s)**

   * –§–∞–π–ª —Å –∞—Å—Å–µ–º–±–ª–µ—Ä–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ CPU.

8. **Assembler**

   * –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—Å—Å–µ–º–±–ª–µ—Ä–Ω—ã–π –∫–æ–¥ –≤ –æ–±—ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª (`.o`).

9. **Object File (.o)**

   * –î–≤–æ–∏—á–Ω—ã–π –º–æ–¥—É–ª—å —Å –º–∞—à–∏–Ω–Ω—ã–º –∫–æ–¥–æ–º, —Ç–∞–±–ª–∏—Ü–∞–º–∏ —Å–∏–º–≤–æ–ª–æ–≤, –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.

10. **Linker**

    * –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ–±—ä–µ–∫—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (.a, .so) –≤ –µ–¥–∏–Ω—ã–π ELF.

11. **Executable (ELF)**

    * –ì–æ—Ç–æ–≤—ã–π –∫ –∑–∞–ø—É—Å–∫—É –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª —Ñ–æ—Ä–º–∞—Ç–∞ ELF.

12. **Loader**

    * –ó–∞–≥—Ä—É–∑–∫–∞ ELF –≤ –ø–∞–º—è—Ç—å —è–¥—Ä–æ–º Linux (`execve`).

13. **Dynamic Linking**

    * –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ (.so) –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

14. **Process**

    * –ó–∞–ø—É—â–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ–≥—Ä–∞–º–º—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

15. **System Calls**

    * –ü—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã –∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤ —è–¥—Ä–æ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ä–µ—Å—É—Ä—Å–∞–º.

16. **Kernel Space**

    * –†–µ–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —è–¥—Ä–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–µ–≥–æ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –≤—ã–∑–æ–≤—ã –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º.

17. **Hardware (–ê–ø–ø–∞—Ä–∞—Ç–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ)**

    * –§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞, –ø–∞–º—è—Ç–∏ –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤.





üîπ –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–ª—è
‚Ä¢	id BIGSERIAL PRIMARY KEY
–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø–∏—Å–∏.
BIGSERIAL –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ ‚Üí —É–¥–æ–±–Ω–æ, –Ω–µ –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å ID.
‚Ä¢	created_at TIMESTAMP NOT NULL DEFAULT NOW()
–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏.
–ù—É–∂–Ω–æ, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å, –∫–æ–≥–¥–∞ —Å—Ç—Ä–æ–∫–∞ –ø–æ—è–≤–∏–ª–∞—Å—å –≤ —Ç–∞–±–ª–∏—Ü–µ.
‚Ä¢	updated_at TIMESTAMP NOT NULL DEFAULT NOW()
–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏.
–û–±—ã—á–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Ç—Ä–∏–≥–≥–µ—Ä–æ–º –ø—Ä–∏ UPDATE, —á—Ç–æ–±—ã –≤—Å–µ–≥–¥–∞ –∑–Ω–∞—Ç—å, –∫–æ–≥–¥–∞ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ –º–µ–Ω—è–ª–∏ –¥–∞–Ω–Ω—ã–µ.
‚Ä¢	is_deleted BOOLEAN NOT NULL DEFAULT FALSE
–§–ª–∞–≥ ‚Äú–º—è–≥–∫–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è‚Äù (soft delete).
–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —Ä–µ–∞–ª—å–Ω–æ —É–¥–∞–ª—è—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏–∑ –±–∞–∑—ã (–∏ —Ç–µ—Ä—è—Ç—å –∏—Å—Ç–æ—Ä–∏—é), –º—ã —Å—Ç–∞–≤–∏–º TRUE, –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å —Å—á–∏—Ç–∞–µ—Ç—Å—è —É–¥–∞–ª—ë–Ω–Ω–æ–π.

‚∏ª

üîπ –ü—Ä–µ–¥–º–µ—Ç–Ω—ã–µ –ø–æ–ª—è –ø–µ—Ä–µ–ø–∏—Å–∏
‚Ä¢	census_date DATE NOT NULL
–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –ø–µ—Ä–µ–ø–∏—Å–∏ –¥–ª—è —ç—Ç–æ–π –∑–∞–ø–∏—Å–∏.
–ù–∞–ø—Ä–∏–º–µ—Ä, 2025-09-24.
‚Ä¢	full_name CHARACTER VARYING(255) NOT NULL
–§–ò–û –∏–ª–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ–ª–æ–≤–µ–∫, –¥–æ–º–æ—Ö–æ–∑—è–π—Å—Ç–≤–æ, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è).
VARCHAR(255) –¥–∞—ë—Ç –≥–∏–±–∫–æ—Å—Ç—å –ø–æ –¥–ª–∏–Ω–µ —Å—Ç—Ä–æ–∫–∏.
‚Ä¢	population_count NUMERIC(12,2)
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—á—Ç—ë–Ω–Ω—ã—Ö –ª—é–¥–µ–π.
NUMERIC(12,2) –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –±–æ–ª—å—à–∏–µ —á–∏—Å–ª–∞ –∏ –¥–∞–∂–µ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –¥—Ä–æ–±–∏ (–µ—Å–ª–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å—á–∏—Ç–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –ª—é–¥–µ–π, –∞ ‚Äú—á–µ–ª–æ–≤–µ–∫–æ-–µ–¥–∏–Ω–∏—Ü—ã‚Äù —Å –≤–µ—Å–æ–º).
‚Ä¢	is_resident BOOLEAN NOT NULL DEFAULT TRUE
–ü—Ä–∏–∑–Ω–∞–∫, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–µ–ª–æ–≤–µ–∫/–æ–±—ä–µ–∫—Ç —Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º (–ø–æ—Å—Ç–æ—è–Ω–Ω–æ –ø—Ä–æ–∂–∏–≤–∞–µ—Ç –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏).
TRUE ‚Üí —Ä–µ–∑–∏–¥–µ–Ω—Ç, FALSE ‚Üí –≤—Ä–µ–º–µ–Ω–Ω–æ –∏–ª–∏ –Ω–µ—Ä–µ–∑–∏–¥–µ–Ω—Ç.
‚Ä¢	stay_interval INTERVAL
–ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2 years 3 months, 5 days).
–ú–æ–∂–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å, —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ —á–µ–ª–æ–≤–µ–∫ –ø—Ä–æ–∂–∏–≤–∞–µ—Ç –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –∏–ª–∏ –∫–∞–∫ –¥–æ–ª–≥–æ –¥–ª–∏—Ç—Å—è –ø–µ—Ä–µ–ø–∏—Å—å –¥–ª—è —ç—Ç–æ–π –∑–∞–ø–∏—Å–∏.

‚∏ª

üëâ –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:
‚Ä¢	–ø–µ—Ä–≤—ã–µ 4 –ø–æ–ª—è ‚Äî —Å–ª—É–∂–µ–±–Ω—ã–µ (—É–¥–æ–±—Å—Ç–≤–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö),
‚Ä¢	–æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –ø—Ä–µ–¥–º–µ—Ç–Ω—ã–µ, –æ–ø–∏—Å—ã–≤–∞—é—Ç —Å—É—â–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–ø–∏—Å–∏.

‚∏ª


================================================================================
–§–ê–ô–õ: alembic.ini
================================================================================

# A generic, single database configuration.

[alembic]
# path to migration scripts
script_location = migrations

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python-dateutil library that can be
# installed by adding `alembic[tz]` to the pip requirements
# string value is passed to dateutil.tz.gettz()
# leave blank for localtime
# timezone =

# max length of characters to apply to the
# 'slug' field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to migrations/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by 'version_path_separator' below.
# version_locations = %(here)s/bar:%(here)s/bat:migrations/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is 'os', which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url = driver://user:pass@localhost/dbname


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using 'black' - use the console_scripts runner, against the 'black' entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

================================================================================
–§–ê–ô–õ: bot.py
================================================================================

import logging
import asyncio
import io
from uuid import uuid4

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import uvicorn

from aiogram import Bot, Dispatcher, F, types, Router
from aiogram.filters import Command, StateFilter
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup

import aiohttp

API_TOKEN = "7903004765:AAEapDcgiLPw8JDt6OxDssIyRzUKsXxH8w8"

# –í–∞—à —ç–Ω–¥–ø–æ–∏–Ω—Ç, –∫—É–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª (multipart/form-data)
YOUR_API_ENDPOINT = "https://api.student-space.ru/api/v1/docs/upload-pdf"

logging.basicConfig(level=logging.INFO)

# ------------------------------------------------------------------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞

bot = Bot(token=API_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
router = Router()

dp.include_router(router)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
locked_users = set()


# ------------------------------------------------------------------------------------
# –°–æ—Å—Ç–æ—è–Ω–∏—è (FSM)

class Form(StatesGroup):
    waiting_for_action = State()
    waiting_for_pdf = State()


# ------------------------------------------------------------------------------------
# –°–æ–∑–¥–∞—ë–º FastAPI-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI()


# ------------------------------------------------------------------------------------
# 1. –•–µ–Ω–¥–ª–µ—Ä /start

@router.message(Command("start"))
async def cmd_start_handler(message: types.Message, state: FSMContext):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏—è –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ waiting_for_action."""
    await state.clear()
    await state.set_state(Form.waiting_for_action)

    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="–ü–µ—Ä–µ—Å–∫–∞–∑", callback_data="retell"),
            InlineKeyboardButton(text="–õ–µ–∫—Ü–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º", callback_data="test")
        ],
        [
            InlineKeyboardButton(text="–í–æ–ø—Ä–æ—Å—ã –ø–æ –ª–µ–∫—Ü–∏—è–º", callback_data="questions"),
            InlineKeyboardButton(text="–ü–µ—Ä–µ–≤–æ–¥", callback_data="translate")
        ]
    ])
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=keyboard)


# ------------------------------------------------------------------------------------
# 2. –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫ (retell, lectures, questions, translate)
#    –°—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ –≤ waiting_for_action, –∏ –≤ waiting_for_pdf.

@router.callback_query(
    F.data.in_({"retell", "test", "questions", "translate"}),
    StateFilter(Form.waiting_for_action, Form.waiting_for_pdf),
)
async def process_action_callback(callback_query: types.CallbackQuery, state: FSMContext):
    action = callback_query.data

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ FSM
    await state.update_data(selected_action=action)

    # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—É—é –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É (–≥–∞–ª–æ—á–∫–∏)
    retell_text = "‚úÖ –ü–µ—Ä–µ—Å–∫–∞–∑" if action == "retell" else "–ü–µ—Ä–µ—Å–∫–∞–∑"
    lectures_text = "‚úÖ –õ–µ–∫—Ü–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º" if action == "test" else "–õ–µ–∫—Ü–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º"
    questions_text = "‚úÖ –í–æ–ø—Ä–æ—Å—ã –ø–æ –ª–µ–∫—Ü–∏—è–º" if action == "questions" else "–í–æ–ø—Ä–æ—Å—ã –ø–æ –ª–µ–∫—Ü–∏—è–º"
    translate_text = "‚úÖ –ü–µ—Ä–µ–≤–æ–¥" if action == "translate" else "–ü–µ—Ä–µ–≤–æ–¥"

    new_keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text=retell_text, callback_data="retell"),
            InlineKeyboardButton(text=lectures_text, callback_data="test")
        ],
        [
            InlineKeyboardButton(text=questions_text, callback_data="questions"),
            InlineKeyboardButton(text=translate_text, callback_data="translate")
        ]
    ])

    current_state = await state.get_state()
    if current_state == Form.waiting_for_action:
        # –ü–µ—Ä–≤—ã–π –≤—ã–±–æ—Ä –¥–µ–π—Å—Ç–≤–∏—è: –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ waiting_for_pdf
        text_for_user = "–í—ã –≤—ã–±—Ä–∞–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ. –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ PDF-—Ñ–∞–π–ª (–¥–æ 5 –ú–ë)."
        await state.set_state(Form.waiting_for_pdf)
    else:
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –£–ñ–ï –≤ waiting_for_pdf –∏ –Ω–∞–∂–∞–ª –¥—Ä—É–≥—É—é –∫–Ω–æ–ø–∫—É ‚Äî
        # –ø—Ä–æ—Å—Ç–æ –º–µ–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ.
        text_for_user = "–í—ã —Å–º–µ–Ω–∏–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ. –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ PDF-—Ñ–∞–π–ª (–¥–æ 5 –ú–ë)."

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    await callback_query.message.edit_text(text=text_for_user, reply_markup=new_keyboard)
    await callback_query.answer()


# ------------------------------------------------------------------------------------
# 3. –ü—Ä–∏—à—ë–ª –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ waiting_for_pdf

@router.message(F.document, Form.waiting_for_pdf)
async def process_pdf_handler(message: types.Message, state: FSMContext):
    user_id = message.from_user.id

    document = message.document
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º PDF
    if document.mime_type != "application/pdf":
        await message.answer("–≠—Ç–æ –Ω–µ PDF-—Ñ–∞–π–ª. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ PDF.")
        return

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ 5 –ú–ë
    if document.file_size > 5 * 1024 * 1024:
        await message.answer("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä ‚Äî 5 –ú–ë.")
        return

    # –î–æ—Å—Ç–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
    data = await state.get_data()
    selected_action = data.get("selected_action", "no_action")

    file_info = await bot.get_file(document.file_id)
    file_bytes = await bot.download_file(file_info.file_path)

    # –ì–æ—Ç–æ–≤–∏–º multipart/form-data
    form_data = aiohttp.FormData()
    form_data.add_field(
        name="file",
        value=file_bytes,
        filename=f"{uuid4()}.pdf",
        content_type="application/pdf"
    )
    form_data.add_field(name="user_id", value=str(user_id))
    form_data.add_field(name="prompt_type", value=selected_action)
    # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –∏ –¥–µ–π—Å—Ç–≤–∏–µ
    # form_data.add_field(name="action", value=selected_action)

    headers = {
        "X-Admin-Header": "FsfY1VXAHrzTXUDZ57yiNrqXkRbF0"
    }

    async with aiohttp.ClientSession() as session:
        try:
            resp = await session.post(YOUR_API_ENDPOINT, headers=headers, data=form_data)
            if resp.status == 200:
                logging.info(f"–§–∞–π–ª –æ—Ç user_id={user_id} —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ API")
            else:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: —Å—Ç–∞—Ç—É—Å {resp.status} (user_id={user_id})")
        except Exception as e:
            logging.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞ user_id={user_id}: {e}")

    await message.answer(
        "PDF –ø–æ–ª—É—á–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä!\n"
        "–¢–µ–ø–µ—Ä—å –ø–æ–¥–æ–∂–¥–∏—Ç–µ, –ø–æ–∫–∞ —Ñ–∞–π–ª –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω.\n"
        "–ü–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã —Å–º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª."
    )


# ------------------------------------------------------------------------------------
# 4. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —à–ª—ë—Ç —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ (–≤–º–µ—Å—Ç–æ PDF), –∫–æ–≥–¥–∞ –º—ã –∂–¥—ë–º PDF

@router.message(StateFilter(Form.waiting_for_pdf))
async def process_non_pdf_handler(message: types.Message):
    await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ PDF-—Ñ–∞–π–ª (–¥–æ 5 –ú–ë).")


# ------------------------------------------------------------------------------------
# 5. –≠–Ω–¥–ø–æ–π–Ω—Ç /external-webhook (–æ—Ç —Å—Ç–æ—Ä–æ–Ω–Ω–µ–≥–æ —Å–µ—Ä–≤–∏—Å–∞)
#    –ó–¥–µ—Å—å –º—ã ¬´—Ä–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º¬ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –º–æ–∂–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª –æ–±—Ä–∞—Ç–Ω–æ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.

@app.post("/external-webhook")
async def external_webhook(request: Request):
    data = await request.json()
    user_id = data.get("user_id")
    file_url = data.get("file_url")

    print(user_id)

    if not user_id:
        return JSONResponse({"ok": False, "error": "user_id is required"}, status_code=400)

    if file_url:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–ø—Ä—è–º—É—é (–º—ã –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ await)

        await bot.send_document(
            chat_id=user_id,
            document=file_url,
            caption="–í–æ—Ç –≤–∞—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª!"
        )

    return {"ok": True}


# ------------------------------------------------------------------------------------
# –ó–∞–ø—É—Å–∫–∞–µ–º –∏ FastAPI, –∏ –±–æ—Ç–∞ –≤–º–µ—Å—Ç–µ –≤ –æ–¥–Ω–æ–º event loop

async def run_fastapi():
    """–ó–∞–ø—É—Å–∫ Uvicorn-—Å–µ—Ä–≤–µ—Ä–∞ (FastAPI) –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ."""
    config = uvicorn.Config(app, host="127.0.0.1", port=8100, log_level="info")
    server = uvicorn.Server(config)
    await server.serve()  # –ë–ª–æ–∫–∏—Ä—É—é—â–µ, –Ω–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ


async def run_bot():
    """–ó–∞–ø—É—Å–∫ aiogram (long polling)."""
    await dp.start_polling(bot)


async def main():
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≤ –æ–¥–Ω–æ–º event loop
    bot_task = asyncio.create_task(run_bot())
    fastapi_task = asyncio.create_task(run_fastapi())
    await asyncio.gather(bot_task, fastapi_task)


if __name__ == "__main__":
    asyncio.run(main())

================================================================================
–§–ê–ô–õ: cmd/app/main.py
================================================================================

import sys
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parents[2]
sys.path.append(str(BASE_DIR))

from internal.app import backend_app  # noqa: E402

app = backend_app()

================================================================================
–§–ê–ô–õ: docker/docker-compose.yml
================================================================================

version: '3.7'

networks:
  clickhouse-net:
    driver: bridge
services:
  zookeeper:
    image: zookeeper:3.9.3
    container_name: zh-zookeeper
    restart: unless-stopped
    networks:
      - clickhouse-net
    ports:
      - "127.0.0.1:2185:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  clickhouse1:
    image: clickhouse/clickhouse-server:latest
    container_name: ch1
    depends_on:
      - zookeeper
    networks:
      - clickhouse-net
    volumes:
      - ./configs:/etc/clickhouse-server/
      - ./init-clickhouse.sh:/docker-entrypoint-initdb.d/init-clickhouse.sh:ro
      - /var/clickhouse_data/ch1:/var/lib/clickhouse
    ports:
      - '127.0.0.1:${MILVUS_GRPC_INTERNAL_PORT}:${MILVUS_GRPC_PORT}'
      - '127.0.0.1:${MILVUS_API_INTERNAL_PORT}:${MILVUS_API_PORT}'
    depends_on:
      - etcd
      - minio
    networks:
      bot_network:
        ipv4_address: ${MILVUS_DOCKER_IP}


  postgres:
    <<: *default
    container_name: postgres
    image: postgres:latest
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - '127.0.0.1:${DB_PORT}:${DB_PORT_INTERNAL}'
    volumes:
      - ./configs:/etc/clickhouse-server/
      - ./init-clickhouse.sh:/docker-entrypoint-initdb.d/init-clickhouse.sh:ro
      - /var/clickhouse_data/ch2:/var/lib/clickhouse
    ports:
      - "127.0.0.1:9992:9000"
      - "127.0.0.1:8125:8123"

  clickhouse3:
    image: clickhouse/clickhouse-server:latest
    container_name: ch3
    depends_on:
      - zookeeper
    networks:
      - clickhouse-net
    volumes:
      - ./configs:/etc/clickhouse-server/
      - ./init-clickhouse.sh:/docker-entrypoint-initdb.d/init-clickhouse.sh:ro
      - /var/clickhouse_data/ch3:/var/lib/clickhouse
    ports:
      - "127.0.0.1:9995:9000"
      - "127.0.0.1:8126:8123"

================================================================================
–§–ê–ô–õ: internal/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: internal/app/__init__.py
================================================================================

from .app import create_app as backend_app

================================================================================
–§–ê–ô–õ: internal/app/app.py
================================================================================

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.exc import DBAPIError, NoResultFound

from internal.config import settings
from internal.config.modules import database
from internal.controller.http.router import api_router
from internal.usecase.utils import (
    database_error_handler,
    database_not_found_handler,
    http_exception_handler,
)
from internal.usecase.utils.responses import DynamicResponse


def create_app() -> FastAPI:
    app = FastAPI(
        title=settings.NAME,
        description=settings.DESCRIPTION,
        version=settings.VERSION,
        openapi_url='{0}/openapi.json'.format(settings.DOCS),
        swagger_ui_parameters=settings.SWAGGER_UI_PARAMETERS,
    )

    if settings.APP_CORS_ORIGINS:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=[
                str(origin)
                for origin in settings.APP_CORS_ORIGINS
            ],
            allow_credentials=True,
            allow_methods=['*'],
            allow_headers=['*'],
        )

    @app.middleware("http")
    async def check_header(request: Request, call_next):
        """
        Function to create and configure a FastAPI application instance.

        This function sets up the FastAPI application and adds necessary configurations, such as the
        middleware used for validating specific HTTP headers. The middleware checks for the existence
        and correctness of a required header key and value in all incoming requests. If the header is
        missing or invalid, the request is rejected with a 403 status code and an appropriate error
        message is returned.

        Returns:
            An instance of the FastAPI application with the defined middleware applied.

        Raises:
            HTTPException: When the required header key is not present or contains an invalid value.
        """
        if settings.DEBUG:
            return await call_next(request)
        required_header_key = "X-Admin-Header"
        required_header_value = settings.ADMIN_KEY

        if request.headers.get(required_header_key) != required_header_value:
            return DynamicResponse.create(
                status_code=403,
                description='Invalid or missing header',
                detail='Forbidden',
            )

        response = await call_next(request)
        return response

    app.include_router(api_router, prefix=settings.API)
    app.dependency_overrides.setdefault(*database.override_session)

    app.add_exception_handler(DBAPIError, database_error_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(NoResultFound, database_not_found_handler)

    return app

================================================================================
–§–ê–ô–õ: internal/config/__init__.py
================================================================================

from .settings import settings
from .modules.milvus import get_milvus_client
from .modules.gpt import get_gpt_client
from .modules.minio import get_minio_client
from .modules.database import get_database_client, override_session

================================================================================
–§–ê–ô–õ: internal/config/modules/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: internal/config/modules/database.py
================================================================================

from typing import Any, AsyncContextManager, AsyncGenerator, Callable

from sqlalchemy import orm
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine

from internal.config import settings
from internal.usecase.utils import get_session

AsyncSessionGenerator = AsyncGenerator[AsyncSession, None]


def async_session(
        url: str, *, wrap: Callable[..., Any] | None = None,  # noqa: WPS318
) -> Callable[..., AsyncSessionGenerator] | AsyncContextManager[Any]:
    engine = create_async_engine(
        url, pool_pre_ping=True, future=True,
    )
    factory = orm.sessionmaker(
        engine, class_=AsyncSession, autoflush=False, expire_on_commit=False,
    )

    async def get_session() -> AsyncSessionGenerator:  # noqa: WPS430, WPS442
        async with factory() as session:
            yield session

    return get_session if wrap is None else wrap(get_session)


override_session = get_session, async_session(settings.migrations_url)


def get_database_client():
    from internal.config import settings
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏
    return async_session(settings.migrations_url)()

================================================================================
–§–ê–ô–õ: internal/config/modules/gpt.py
================================================================================

# –§–∞–±—Ä–∏–∫–∞ –¥–ª—è MinioClient
from internal.config import settings
from package.openai import ChatGPTClient, PromptManager
from pydantic import SecretStr

manager_prompt = PromptManager()
system_prompt = manager_prompt.get_prompt('test')

api_key = SecretStr(settings.OPENAI_TOKEN)
client = ChatGPTClient(
    api_key,
    model_name='gpt-4o-mini',
    embeddings_model_name='text-embedding-ada-002',
    system_prompt=system_prompt,
)


def get_gpt_client() -> ChatGPTClient:
    return client

================================================================================
–§–ê–ô–õ: internal/config/modules/milvus.py
================================================================================

# –§–∞–±—Ä–∏–∫–∞ –¥–ª—è MinioClient
from internal.config import settings
from package.milvus import MilvusClient
from package.milvus.main import MilvusClient

milvus_client = MilvusClient(host=settings.MILVUS_HOST, port=settings.MILVUS_PORT)


def get_milvus_client() -> MilvusClient:
    return milvus_client

================================================================================
–§–ê–ô–õ: internal/config/modules/minio.py
================================================================================

# –§–∞–±—Ä–∏–∫–∞ –¥–ª—è MinioClient
from internal.config import settings
from package.minio.main import MinioClient

minio_client = MinioClient(
    endpoint=f"{settings.MINIO_HOST}:{settings.MINIO_PORT}",
    access_key=settings.MINIO_ACCESS_KEY,
    secret_key=settings.MINIO_SECRET_KEY,
)


def get_minio_client() -> MinioClient:
    return minio_client

================================================================================
–§–ê–ô–õ: internal/config/settings.py
================================================================================

from typing import ClassVar, Optional

from pydantic import Field, PostgresDsn, field_validator, RedisDsn
from pydantic_core.core_schema import ValidationInfo
from pydantic_settings import BaseSettings

buckets = {
    'pdf': 'pdf-bucket',
    'tmp': 'tmp'
}

MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB


class Settings(BaseSettings):
    API: str = '/api'
    DOCS: str = '/docs'
    STARTUP: str = 'startup'
    SHUTDOWN: str = 'shutdown'
    COLLECTION_NAME: str = 'pdf_embeddings'

    NAME: str = 'Atlas Backend'
    VERSION: str = '0.1.0'
    DESCRIPTION: str = 'Atlas Backend'
    SWAGGER_UI_PARAMETERS: ClassVar[dict] = {'filter': True, 'displayRequestDuration': True}
    APP_CORS_ORIGINS: None = None
    ADMIN_KEY: str = Field('234df$13r', description='Key for get admin access.')
    DEBUG: bool = Field(False, description='Debug mode.')
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—ÖMutable default '[]' is not allowed. Use 'default_factory
    DB_HOST: str = Field(..., alias='DB_DOCKER_IP', description='–•–æ—Å—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.')
    DB_PORT: int = Field(..., description='–ü–æ—Ä—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.')
    DB_USER: str = Field(..., description='–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.')
    DB_PASSWORD: str = Field(..., description='–ü–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.')
    DB_NAME: str = Field(..., description='–ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.')
    DB_URI: Optional[PostgresDsn] = Field(None, description='URI –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Minio
    MINIO_HOST: str = Field('localhost', alias='MINIO_DOCKER_IP', description='Minio host for set connection.')
    MINIO_PORT: int = Field(5432, description='Default port for MinIO S3 server connection.')
    MINIO_ACCESS_KEY: str = Field(..., description='Minio access token.')
    MINIO_SECRET_KEY: str = Field(..., description='Minio secret token.')
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ OpenAI
    OPENAI_TOKEN: str = Field(..., description='OpenAI API Bearer token.')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Milvus
    MILVUS_HOST: str = Field('127.0.0.1', alias='MILVUS_DOCKER_IP', description='Milvus host for set connection.')
    MILVUS_PORT: int = Field(9091, alias='MILVUS_GRPC_PORT', description='Milvus port for set connection.')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Redis
    REDIS_HOST: str = Field('127.0.0.1', alias='REDIS_DOCKER_IP', description='Redis host for set connection.')
    REDIS_PORT: int = Field(..., description='Redis port for set connection.')
    REDIS_NAME: str = Field(..., description='Redis name for set connection.')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Celery
    CELERY_RESULT_BACKEND: RedisDsn | str | None = Field(None, description='Celery result backend URL.')
    CELERY_BROKER_URL: RedisDsn | str | None = Field(None, description='Celery broker URL.')

    TELEGRAM_WEBHOOK: str = Field('https://localhost', description='Telegram webhook for send data.')

    @field_validator('DB_URI', mode='before')
    @classmethod
    def assemble_db_connection(
            cls, value: str | None, values: ValidationInfo,  # noqa: WPS110
    ) -> str | PostgresDsn:
        if isinstance(value, str):
            return value

        return PostgresDsn.build(
            scheme='postgresql+asyncpg',
            username=values.data.get('DB_USER'),
            password=values.data.get('DB_PASSWORD'),
            host=values.data.get('DB_HOST'),
            port=values.data.get('DB_PORT'),
            path=str(values.data.get('DB_NAME')),
        )

    @field_validator('CELERY_RESULT_BACKEND', 'CELERY_BROKER_URL', mode='before')
    @classmethod
    def assemble_celery_connection(cls, value: str | None, values: ValidationInfo) -> str | RedisDsn:
        return RedisDsn.build(
            scheme='redis',
            host=values.data.get('REDIS_HOST'),
            port=values.data.get('REDIS_PORT'),
            path=str(values.data.get('REDIS_NAME')),
        )

    @property
    def migrations_url(self) -> str:
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç PostgresDsn –≤ —Å—Ç—Ä–æ–∫—É
        return str(self.DB_URI)

    class Config(object):
        env_file = '.env'
        env_file_encoding = 'utf-8'
        extra = 'ignore'


settings = Settings()

================================================================================
–§–ê–ô–õ: internal/controller/http/router.py
================================================================================

from fastapi import APIRouter

from internal.controller.http import v1

api_router = APIRouter()
api_router.include_router(v1.router, prefix='/v1')

================================================================================
–§–ê–ô–õ: internal/controller/http/v1/__init__.py
================================================================================

from fastapi import APIRouter, Depends
from .docs import router as docs_router

# router = APIRouter(dependencies=[Depends(dependencies.authorize_user)]) # noqa: E800

router = APIRouter()

router.include_router(docs_router, prefix='/docs')

================================================================================
–§–ê–ô–õ: internal/controller/http/v1/docs.py
================================================================================

import uuid

from fastapi import APIRouter, UploadFile, File, Depends, Form

from internal.config.modules.minio import get_minio_client
from internal.config.settings import buckets, MAX_FILE_SIZE
from internal.dto.celery import TaskRunInfo
from internal.dto.docs import DocsCreate
from internal.service.docs import DocsService
from internal.usecase.utils.responses import HTTP_400_BAD_REQUEST, HTTP_200_OK_REQUEST, DynamicResponse
from package.minio.main import MinioClient
from package.celery.worker import process_document

# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Router –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –¥–∞–Ω–Ω–æ–≥–æ –º–æ–¥—É–ª—è
router = APIRouter()


@router.post(
    "/upload-pdf",
    summary="–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ PDF —Ñ–∞–π–ª–∞",
    responses={
        **HTTP_400_BAD_REQUEST.schema(
            status_code=400,
            description='Failed to upload file.',
            example={"detail": "Invalid MIME type. Expected application/pdf."}
        ),
        **HTTP_200_OK_REQUEST.schema(
            status_code=200,
            description='Success',
            example={"id": "1234567890", "filename": "example.pdf", "filesize": 1024}
        ),
    },
    tags=["PDF Upload"])
async def upload_pdf(
        user_id: str = Form(...),  # user_id –ø—Ä–∏—Ö–æ–¥–∏—Ç –∏–∑ —Ñ–æ—Ä–º—ã
        prompt_type: str = Form(...),
        file: UploadFile = File(...),  #
        service: DocsService = Depends(DocsService),
        minio_client: MinioClient = Depends(get_minio_client),
):
    """
    Handles the upload of a PDF file, validates its MIME type and size, and stores
    the file in a specified bucket. The function initiates a background task for
    processing the uploaded document and returns a response with task details or
    an appropriate error message if validation or file upload fails.

    Args:
        user_id (str): The ID of the user uploading the file.
        file (UploadFile): An uploaded file object to be validated and processed.
        service (DocsService): A dependency injection providing access to the
            document service.
        minio_client (MinioClient): A dependency injection providing access to
            the MinIO client.
        prompt_type (str): The type of the prompt.

    Returns:
        DynamicResponse: A dynamic response indicating the result of the request.
        On success (200): Includes task information, target file name, and
            file size in task details.
        On failure (400): Includes details of the failure and corresponding
            messages such as MIME type verification or file size violations.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –∏–º–µ–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .pdf
    if file.content_type != "application/pdf":
        return DynamicResponse.create(status_code=400, description='Invalid MIME type. Expected application/pdf.')

    if file.size >= MAX_FILE_SIZE:
        return DynamicResponse.create(
            status_code=400,
            description='File size exceeds the limit.',
            detail=f'File size must be less than {MAX_FILE_SIZE / 1024} KB.',
        )

    bucket = buckets.get('tmp')
    object_name = f"{uuid.uuid4()}.pdf"
    s3_briefly = f"{bucket}/{object_name}"

    doc_data = DocsCreate(
        name=object_name,
        s3_briefly=s3_briefly,
    )
    try:
        await service.transaction_to_minio(
            minio_client=minio_client,
            dto=doc_data,
            bucket=bucket,
            file=file.file,
        )
        task = process_document.delay(object_name, bucket, user_id, prompt_type)
        task_info = TaskRunInfo(id=task.id, filename=object_name, filesize=file.size)
        return DynamicResponse.create(
            status_code=200,
            detail='Success',
            description='File successfully uploaded.',
            example=task_info.model_dump())
    except Exception as e:
        return DynamicResponse.create(status_code=400, detail="Bad Request", description=str(e))

================================================================================
–§–ê–ô–õ: internal/dto/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: internal/dto/celery.py
================================================================================

from pydantic import BaseModel


class TaskRunInfo(BaseModel):
    id: str
    filename: str
    filesize: float | int

================================================================================
–§–ê–ô–õ: internal/dto/docs.py
================================================================================

from typing import Optional
from uuid import UUID
from pydantic import BaseModel


class DocsRead(BaseModel):
    id: UUID
    name: str
    s3_briefly: str

    class Config:
        from_attributes = True


class DocsCreate(BaseModel):
    """
    Represents a model for creating documentation files with a name and an S3 path.

    The class is designed to handle file metadata, including its name and S3
    storage path. It extends the BaseModel to provide model-related functionality
    and supports configuration settings to allow creating instances from
    class attributes.
    """
    name: str  # –ò–º—è —Ñ–∞–π–ª–∞
    s3_briefly: str  # –ü—É—Ç—å –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ S3

    class Config:
        from_attributes = True


class MilvusDocsCreate(BaseModel):
    """
    Represents a model for mapping Milvus IDs to document IDs.

    This class is designed to facilitate the integration and mapping between
    Milvus, a high-performance vector database, and document storage systems. Each
    instance of this class links a unique ID used in Milvus to a corresponding
    document ID. It ensures that both identifiers are consistently paired and can
    be utilized for further operations like querying or storage manipulation.

    Attributes:
        milvus_id (int): The unique identifier associated with an entry in the
            Milvus database.
        docs_id (int): The unique identifier associated with a document in the
            document storage system.

    Config:
        from_attributes (bool): Determines whether an instance of the class can
            be created from attributes directly. This is primarily used to enable
            flexibility in the data parsing and instantiation process.
    """
    milvus_id: int
    docs_id: int

    class Config:
        from_attributes = True


class MilvusDocsRead(BaseModel):
    """
    Represents a model for linking Milvus entries with document data.

    This class is used to represent a relationship between a Milvus entry and
    its corresponding document data. It contains references to the Milvus ID,
    a unique document identifier (UUID), and optionally, the associated
    document data. It is primarily intended for use as part of a database
    model or data-access-layer structure.

    Attributes:
        milvus_id: int
            The ID representing the entry in the Milvus system.
        docs_id: UUID
            The universally unique identifier (UUID) representing the
            associated document.
        docs: Optional[DocsRead]
            The optional data associated with the document referenced by
            the docs_id.

    Config:
        from_attributes: bool
            Enables mapping model attributes directly from an instance.
        arbitrary_types_allowed: bool
            Permits arbitrary types for properties in the model.
    """
    milvus_id: int
    docs_id: UUID  # UUID –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –∫–ª—é—á–∞
    docs: Optional[DocsRead] = None  # –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã Docs

    class Config:
        from_attributes = True
        arbitrary_types_allowed = True

================================================================================
–§–ê–ô–õ: internal/entity/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: internal/entity/base.py
================================================================================

from re import sub

import sqlalchemy as sa
from sqlalchemy import MetaData
from sqlalchemy.dialects import postgresql as psql
from sqlalchemy.ext.declarative import as_declarative, declared_attr


@as_declarative()
class Base(object):

    __name__: str
    metadata: MetaData

    @classmethod
    @declared_attr
    def __tablename__(cls):
        return sub('(?<!^)(?=[A-Z])', '_', cls.__name__).lower()

    id = sa.Column(
        psql.UUID(as_uuid=True),
        server_default=sa.text('gen_random_uuid()'),
        primary_key=True,
        index=True,
    )

================================================================================
–§–ê–ô–õ: internal/entity/docs.py
================================================================================

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql as psql

from internal.entity.base import Base
from internal.entity.mixin import TimestampMixin
from sqlalchemy.orm import relationship


class Docs(TimestampMixin, Base):
    name = sa.Column(sa.String(255), nullable=True)
    checksum = sa.Column(sa.BigInteger, nullable=True)
    s3_briefly = sa.Column(sa.String(255), nullable=True)
    milvus_docs = relationship('MilvusDocs', back_populates='docs', uselist=True)


class MilvusDocs(TimestampMixin, Base):
    id = ...
    milvus_id = sa.Column(sa.BigInteger, primary_key=True)
    docs_id = sa.Column(psql.UUID(as_uuid=True), sa.ForeignKey('docs.id'), nullable=False)
    docs = relationship('Docs', back_populates='milvus_docs')

================================================================================
–§–ê–ô–õ: internal/entity/mixin.py
================================================================================

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql as psql
from sqlalchemy.orm import declarative_mixin


@declarative_mixin
class TimestampMixin(object):

    created_at = sa.Column(
        psql.TIMESTAMP(timezone=True),
        default=sa.func.now(),
        server_default=sa.FetchedValue(),
    )
    updated_at = sa.Column(
        psql.TIMESTAMP(timezone=True),
        onupdate=sa.func.now(),
        server_default=sa.FetchedValue(),
        server_onupdate=sa.FetchedValue(),
    )
    deleted_at = sa.Column(
        psql.TIMESTAMP(timezone=True), server_default=sa.FetchedValue(),
    )

================================================================================
–§–ê–ô–õ: internal/service/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: internal/service/docs.py
================================================================================

from typing import Dict, Any

import sqlalchemy as sa
from sqlalchemy.orm import selectinload
from internal.dto.docs import DocsCreate, DocsRead
from internal.entity.docs import Docs, MilvusDocs
from internal.service.service import Service
from package.minio.main import MinioClient


class DocsService(Service[Docs]):
    async def transaction_to_minio(self, minio_client: MinioClient, dto: DocsCreate, bucket: str, file) -> Docs:
        """
        Handles the process of saving a transaction in PostgreSQL and uploading a file
        to an MinIO bucket. This involves creating a model instance using the input data,
        storing it in the database, uploading the file, and rolling back the MinIO upload
        if database commit fails.

        Parameters:
            minio_client (MinioClient): The client used for interacting with the MinIO storage service.
            dto (DocsCreate): The data transfer object containing the fields necessary for creating the database entry.
            bucket (str): The name of the MinIO bucket where the file will be uploaded.
            file: The file object that is to be uploaded to MinIO.

        Raises:
            Exception: Propagates any exceptions that occur during the transaction and rollback processes.

        Returns:
            instance: The created database object that successfully corresponds to the input data and uploaded file.
        """
        instance = self.model(**dto.dict())
        self.session.add(instance)

        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ MinIO
        minio_client.upload_file_to_bucket(
            bucket_name=bucket,
            file_io=file,
            object_name=instance.name,
        )

        try:
            # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∑–∏–ª–∏ –≤ MinIO, —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –≤ Postgres
            await self.session.commit()
        except Exception as e:
            # –ï—Å–ª–∏ commit –≤ Postgres –Ω–µ —É–¥–∞–ª—Å—è, —É–¥–∞–ª—è–µ–º —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            minio_client.delete_file_from_bucket(bucket, instance.name)
            raise e  # –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
        return instance

    async def create_docs_and_milvus(self, dto: DocsCreate, milvus_ids: list[int]) -> dict[str, Any]:
        """
        Creates a record in the `Docs` table and a related record in the
        `MilvusDocs` table within a single transactional context. All operations
        are committed atomically, ensuring data consistency. In case of an
        exception, the entire transaction is rolled back.

        Args:
            dto (DocsCreate): Data transfer object containing attributes for the
                `Docs` model.
            milvus_ids (list[int]): Identifier to associate the `Docs` record with a
                `MilvusDocs` record.

        Raises:
            Exception: Any exceptions that occur during execution, resulting in a
                rollback of the transaction.

        Returns:
            DocsCreate: Instance of the newly created `Docs` record.
        """

        # –°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å –≤ —Ç–∞–±–ª–∏—Ü–µ Docs
        instance = self.model(**dto.dict())
        self.session.add(instance)
        await self.session.commit()
        instance_set = [
            MilvusDocs(docs_id=instance.id, milvus_id=pk) for pk in milvus_ids
        ]
        self.session.add_all(instance_set)
        await self.session.commit()

        # –û–∂–∏–¥–∞–Ω–∏–µ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–¥–µ–ª–∞–µ—Ç commit –≤ –∫–æ–Ω—Ü–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)

        return DocsRead.model_validate(instance).model_dump()


class MilvusDocsService(Service[MilvusDocs]):

    async def get_one_or_none(self, milvus_id: int, *where, **filter_by):
        """
        Retrieve a single record based on the given conditions or return None if no matching record is found.

        The method executes a database query using SQLAlchemy to select a record from the model
        based on the milvus_id, optional filtering conditions, and optional filtering parameters.
        It allows for a flexible query construction using where clauses and filter_by conditions.

        Args:
            milvus_id (int): The unique identifier to filter the record by.
            *where: Additional positional filtering conditions to apply to the query.
            **filter_by: Additional named parameters for filtering the query.

        Returns:
            The selected scalar record if it exists, otherwise None.
        """
        return await self.session.scalar(
            sa.select(self.model).options(selectinload(MilvusDocs.docs)).filter_by(
                milvus_id=milvus_id, **filter_by,
            ).where(*where),
        )

================================================================================
–§–ê–ô–õ: internal/service/service.py
================================================================================

from typing import Generic, TypeVar, get_args
from uuid import UUID

import sqlalchemy as sa
from fastapi import Depends
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession

from internal.entity.base import Base
from internal.usecase.utils import exceptions, get_session
from package.pagination import Params

T = TypeVar('T')


class Service(Generic[T]):  # noqa: WPS214, WPS338

    model: Base

    def __init__(self, session: AsyncSession = Depends(get_session)):
        self.session = session

    def __init_subclass__(cls):
        cls.model = get_args(cls.__orig_bases__[0])[0]

    def raise_not_found(self) -> None:
        raise exceptions.HTTP_404_NOT_FOUND(
            'Not found {0}'.format(self.model.__name__),
        )

    async def get_one(self, id: UUID, *where, **filter_by) -> T:
        instance = await self.get_one_or_none(id, *where, **filter_by)
        if instance is None:
            self.raise_not_found()

        return instance

    async def get_one_or_none(self, id: UUID, *where, **filter_by) -> T | None:
        return await self.session.scalar(
            sa.select(self.model).filter_by(
                id=id, deleted_at=None, **filter_by,
            ).where(*where),
        )

    async def select(self, dto: Params, *where, **filter_by) -> tuple[list[T], int]:
        instance_set = await self.session.scalars(
            sa.select(self.model).where(*where).filter_by(
                deleted_at=None, **filter_by,
            ).limit(dto.limit).offset(dto.offset),
        )
        return instance_set.unique().all(), await self.count(*where)

    async def select_all(self, *where, **filter_by) -> list[T]:
        instance_set = await self.session.scalars(
            sa.select(self.model).filter_by(deleted_at=None, **filter_by).where(*where),
        )
        return instance_set.unique().all()

    async def create(self, dto: BaseModel) -> T:
        instance = self.model(**dto.dict())
        self.session.add(instance)
        await self.session.commit()

        return instance

    async def create_many(self, dto_set: list[BaseModel]) -> list[T]:
        instance_set = [self.model(**dto.dict()) for dto in dto_set]
        self.session.add_all(instance_set)
        await self.session.commit()

        return instance_set

    async def update(self, id: UUID, **values) -> T:
        await self.session.execute(
            sa.update(self.model).filter_by(id=id).values(**values),
        )
        await self.session.commit()

        return await self.get_one(id)

    async def delete(self, id: UUID) -> None:
        await self.get_one(id)

        await self.session.execute(
            sa.update(self.model).filter_by(id=id).values(deleted_at=sa.func.now()),
        )
        await self.session.commit()

    async def count(self, *where, **filter_by) -> int:
        return await self.session.scalar(
            sa.select(sa.func.count(self.model.id)).filter_by(
                **filter_by, deleted_at=None,
            ).where(*where),
        )

================================================================================
–§–ê–ô–õ: internal/service/utils.py
================================================================================

from contextlib import asynccontextmanager

from internal.config.modules.database import get_database_client


@asynccontextmanager
async def get_service(service_class):
    """
    An asynchronous context manager for obtaining and managing a service instance.

    This function is designed to provide a service instance of the specified
    service class, utilizing a session created by the asynchronous database client.
    It ensures proper cleanup of the session once the context is exited. This
    function supports dependency injection by creating the service with the session
    as its initialization parameter.

    Args:
        service_class: The class of the service to be managed. This should be a
        subclass of `Service`.

    Yields:
        An instance of the provided `service_class`, initialized with the session.

    Raises:
        Any exceptions raised within the context will propagate back to the caller.
    """
    async for session in get_database_client():
        service = service_class(session)
        try:
            yield service
        finally:
            await session.close()

================================================================================
–§–ê–ô–õ: internal/usecase/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: internal/usecase/utils/__init__.py
================================================================================

from .exceptions import *
from .mocks import get_session
from .responses import (
    ResponseExample,
    ResponseSchema,
    SuccessfulResponse,
)

================================================================================
–§–ê–ô–õ: internal/usecase/utils/exceptions/__init__.py
================================================================================

from .exceptions import (
    HTTP_400_BAD_REQUEST,
    HTTP_401_UNAUTHORIZED,
    HTTP_403_FORBIDDEN,
    HTTP_404_NOT_FOUND,
)
from .handlers import (
    database_error_handler,
    database_not_found_handler,
    http_exception_handler,
)

================================================================================
–§–ê–ô–õ: internal/usecase/utils/exceptions/exceptions.py
================================================================================

from fastapi import HTTPException, status


class HTTPException(HTTPException):  # noqa: WPS440

    def __call__(self, detail: str) -> HTTPException:
        return HTTPException(self.status_code, detail)


HTTP_400_BAD_REQUEST = HTTPException(
    detail='Bad Request',
    status_code=status.HTTP_400_BAD_REQUEST,
)
HTTP_401_UNAUTHORIZED = HTTPException(
    detail='Unauthorized',
    status_code=status.HTTP_401_UNAUTHORIZED,
)
HTTP_403_FORBIDDEN = HTTPException(
    detail='Forbidden',
    status_code=status.HTTP_403_FORBIDDEN,
)
HTTP_404_NOT_FOUND = HTTPException(
    detail='Not Found',
    status_code=status.HTTP_404_NOT_FOUND,
)

================================================================================
–§–ê–ô–õ: internal/usecase/utils/exceptions/handlers.py
================================================================================

from fastapi import HTTPException, Request, status
from fastapi.responses import JSONResponse
from sqlalchemy.exc import DBAPIError, NoResultFound


async def database_error_handler(
        _: Request, exc: DBAPIError,
) -> JSONResponse:
    detail = str(exc.orig).split('DETAIL:  ')[-1].rstrip('.')
    return JSONResponse(
        content={'detail': detail},
        status_code=status.HTTP_400_BAD_REQUEST,
    )


async def database_not_found_handler(
        _: Request, exc: NoResultFound,
) -> JSONResponse:
    return JSONResponse(
        content={'detail': str(exc)},
        status_code=status.HTTP_404_NOT_FOUND,
    )


async def http_exception_handler(
        _: Request, exc: HTTPException,
) -> JSONResponse:
    response = JSONResponse(
        content={'detail': exc.detail},
        status_code=exc.status_code,
    )
    if exc.headers is not None:
        response.init_headers(exc.headers)

    return response

================================================================================
–§–ê–ô–õ: internal/usecase/utils/mocks.py
================================================================================

def get_session():
    raise NotImplementedError

================================================================================
–§–ê–ô–õ: internal/usecase/utils/responses.py
================================================================================

from typing import Any, Dict, TypedDict

from fastapi import status
from fastapi.responses import Response
from typing_extensions import NotRequired

from fastapi.responses import JSONResponse


class DynamicResponse:

    @staticmethod
    def schema(status_code: int, description: str, example: dict) -> dict:
        """
        This static method generates a structured dictionary schema for an HTTP response, which includes the status code,
        description of the response, and an example payload. It organizes the data in a manner consistent with common API
        documentation formats.

        Arguments:
            status_code (int): The HTTP status code to be included in the response schema.
            description (str): A textual description associated with the provided status code.
            example (dict): A sample JSON payload illustrating the response structure and data.

        Returns:
            dict: A dictionary structure representing the HTTP response schema, formatted for API documentation purposes.
        """
        return {
            status_code: {
                'description': description,
                'content': {
                    'application/json': {
                        'data': example,
                    },
                },
            },
        }

    @staticmethod
    def create(
            status_code: int,
            detail: str,
            description: str = '',
            example: dict = None,
    ) -> JSONResponse:
        """
            Creates a JSONResponse object configured with a specific status code,
            description, detail message, and optional example content. This method
            provides a structured response format for JSON-based API responses.

            Parameters:
            status_code: int
                The HTTP status code to include in the response.
            description: str
                A brief description of the response.
            detail: str
                A detailed message or additional information to include in the response content.
            example: dict, optional
                Example data to include in the response. If not provided, a default
                dictionary with only the detail message will be used.

            Returns:
            JSONResponse
                A JSONResponse object containing the provided status code, description,
                and structured content with the example data.
        """
        if example is None:
            example = {}

        # –ù–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã–º–∏
        example['detail'] = detail

        # –í–æ–∑–≤—Ä–∞—â—è–µ–º JSONResponse –≤ —Ç—Ä–µ–±—É–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        return JSONResponse(
            status_code=status_code,
            content={
                "status_code": status_code,
                "description": description,
                "content": {
                    "application/json": {
                        "data": example,
                    },
                },
            },
        )


class ResponseExample(TypedDict):
    detail: NotRequired[str]


class ResponseSchema(dict):  # noqa: WPS600

    def __init__(
            self,
            status_code: int,
            description: str,
            example: ResponseExample,
    ) -> None:
        self.example = example
        self.status_code = status_code
        self.description = description
        super().__init__(self.schema(
            example=example,
            status_code=status_code,
            description=description,
        ))

    def __call__(self, detail: str = '', description: str = ''):
        example = self.example.copy()
        example['detail'] = detail or example['detail']
        return self.schema(
            example=example,
            status_code=self.status_code,
            description=description or self.description,
        )

    @classmethod
    def schema(
            cls,
            status_code: int,
            description: str,
            example: ResponseExample,
    ) -> Dict[int, Dict[str, Any]]:
        return {
            status_code: {
                'description': description,
                'content': {
                    'application/json': {
                        'data': example,
                    },
                },
            },
        }


class SuccessfulResponse(Response):

    def __init__(self, status_code: int = status.HTTP_204_NO_CONTENT):
        super().__init__(status_code=status_code)


HTTP_200_OK_REQUEST = ResponseSchema(
    status_code=status.HTTP_200_OK,
    description='OK',
    example=ResponseExample(detail='OK'),
)

HTTP_400_BAD_REQUEST = ResponseSchema(
    status_code=status.HTTP_400_BAD_REQUEST,
    description='Bad Request',
    example=ResponseExample(detail='Bad Request'),
)
HTTP_403_FORBIDDEN = ResponseSchema(
    status_code=status.HTTP_403_FORBIDDEN,
    description='Forbidden',
    example=ResponseExample(detail='Forbidden'),
)
HTTP_404_NOT_FOUND = ResponseSchema(
    status_code=status.HTTP_404_NOT_FOUND,
    description='Not Found',
    example=ResponseExample(detail='Not Found'),
)

================================================================================
–§–ê–ô–õ: internal/usecase/utils/tools.py
================================================================================

def convert_size(size: int, unit: str) -> float:
    """
    Convert a file size from bytes into a human-readable string representation based on the provided
    unit of measurement. A specific representation, expressed in bytes, kilobytes, megabytes, gigabytes,
    or terabytes, is returned formatted to two decimal places.

    Args:
        size (int): File size in bytes to be converted.
        unit (str): Unit index indicating the conversion level (0 for bytes, 1 for kilobytes,
                    2 for megabytes, 3 for gigabytes, 4 for terabytes).

    Returns:
        str: The file size formatted as a string with the specified unit.
    """
    return float("{:.2f}".format(
        size / 1024 ** 0 if unit == 'B' else 1 if unit == 'KB' else 2 if unit == 'MB' else 3 if unit == 'GB' else 4
    ))


================================================================================
–§–ê–ô–õ: main.py
================================================================================

import asyncio
import logging

from package.milvus import MilvusClient

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MILVUS_HOST = 'localhost'
MILVUS_PORT = '19530'
COLLECTION_NAME = 'pdf_embeddings'
DIMENSION = 1536


async def main():
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Milvus
    milvus_client = MilvusClient(host=MILVUS_HOST, port=MILVUS_PORT)
    # result = milvus_client.get_all_vectors(collection_name=COLLECTION_NAME)
    # for item in result:
    #     print(item)
    milvus_client.drop_collection('pdf_embeddings')
    milvus_client.create_collection('pdf_embeddings', DIMENSION)


if __name__ == '__main__':
    asyncio.run(main())

================================================================================
–§–ê–ô–õ: make/compose.Makefile
================================================================================

.PHONY: compose-build
compose-build: ## Build or rebuild services
	docker compose -f docker/docker-compose.yml --env-file $(ENV_FILE) build

.PHONY: compose-up-build
compose-up-build: ## Create and start containers
	docker compose -f docker/docker-compose.yml --env-file $(ENV_FILE) up -d --build

.PHONY: compose-up
compose-up: ## Create and start containers
	docker compose -f docker/docker-compose.yml --env-file $(ENV_FILE) up -d

.PHONY: compose-migration
compose-migration: ## Create and start containers
	docker compose -f docker/docker-compose.yml --env-file $(ENV_FILE) up migration --exit-code-from migration

.PHONY: compose-logs
compose-logs: ## View output from containers
	docker compose -f docker/docker-compose.yml logs

.PHONY: compose-ps
compose-ps: ## List containers
	docker compose -f docker/docker-compose.yml ps

.PHONY: compose-ls
compose-ls: ## List running compose projects
	docker compose -f docker/docker-compose.yml ls

.PHONY: compose-start
compose-start: ## Start services
	docker compose -f docker/docker-compose.yml --env-file $(ENV_FILE) start

.PHONY: compose-restart
compose-restart: ## Restart services
	docker cp ./ tarvos-api:/code/
	docker compose -f docker/docker-compose.yml restart

.PHONY: compose-stop
compose-stop: ## Stop services
	docker compose -f docker/docker-compose.yml stop

.PHONY: compose-down
compose-down: ## Stop and remove containers, networks
	docker compose -f docker/docker-compose.yml down --remove-orphans

================================================================================
–§–ê–ô–õ: make/docker.Makefile
================================================================================

.PHONY: docker-clean
docker-clean: ## Remove unused data
	docker system prune -a

================================================================================
–§–ê–ô–õ: make/lint.Makefile
================================================================================

.PHONY: lint
lint: ## Run linters
	make lint-isort
	make lint-flake

.PHONY: lint-isort
lint-isort: ## Run isort linter
	isort .

.PHONY: lint-flake8
lint-flake:  ## Run flake8 linter
	flake8

================================================================================
–§–ê–ô–õ: make/migration.Makefile
================================================================================

.PHONY: migrate-create
migrate-create: ## Create new migration
	alembic revision --autogenerate -m $(name)

.PHONY: migrate-history
migrate-history: ## Migration history
	alembic history

.PHONY: migrate-up
migrate-up: ## Migration up
	alembic upgrade head

.PHONY: migrate-down
migrate-down: ## Migration down
	alembic downgrade -1

================================================================================
–§–ê–ô–õ: make/run.Makefile
================================================================================

.PHONY: run
run: ## Run application
	gunicorn \
	    --bind $(APP_HOST):$(APP_PORT_INTERNAL) \
		--worker-class uvicorn.workers.UvicornWorker \
		--workers $(APP_WORKERS) \
		--log-level $(APP_LOG_LEVEL) \
		--chdir cmd/app \
		main:app

.PHONY: run-dev
run-dev: ## Run application in development mode
	uvicorn --app-dir cmd/app main:app --reload --host 0.0.0.0

================================================================================
–§–ê–ô–õ: make/test.Makefile
================================================================================

.PHONY: test
test: ## Run pytest
	poetry run pytest -rs --junitxml=reports/test-report.xml

.PHONY: test-coverage
test-coverage: ## Run pytest coverage
	poetry run coverage run -m pytest -rs --junitxml=reports/test-report.xml
	poetry run coverage report
	poetry run coverage xml -o reports/coverage.xml
	poetry run coverage html -d reports/coverage/

================================================================================
–§–ê–ô–õ: migrations/README
================================================================================

Generic single-database configuration.

================================================================================
–§–ê–ô–õ: migrations/script.py.mako
================================================================================

"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ''}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else 'pass'}


def downgrade() -> None:
    ${downgrades if downgrades else 'pass'}

================================================================================
–§–ê–ô–õ: migrations/versions/c9309fddd1ae_initial.py
================================================================================

"""initial

Revision ID: c9309fddd1ae
Revises: 
Create Date: 2025-01-06 02:57:11.472461

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from sqlalchemy.schema import FetchedValue

# revision identifiers, used by Alembic.
revision: str = 'c9309fddd1ae'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('docs',
                    sa.Column('name', sa.String(length=255), nullable=True),
                    sa.Column('checksum', sa.BigInteger(), nullable=True),
                    sa.Column('s3_briefly', sa.String(length=255), nullable=True),
                    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=FetchedValue(),
                              nullable=True),
                    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=FetchedValue(),
                              nullable=True),
                    sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), server_default=FetchedValue(),
                              nullable=True),
                    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
                    sa.PrimaryKeyConstraint('id')
                    )
    op.create_index(op.f('ix_docs_id'), 'docs', ['id'], unique=False)
    op.create_table('milvus_docs',
                    sa.Column('milvus_id', sa.BigInteger(), nullable=False),
                    sa.Column('docs_id', sa.UUID(), nullable=False),
                    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=FetchedValue(),
                              nullable=True),
                    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=FetchedValue(),
                              nullable=True),
                    sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), server_default=FetchedValue(),
                              nullable=True),
                    sa.ForeignKeyConstraint(['docs_id'], ['docs.id'], ),
                    sa.PrimaryKeyConstraint('milvus_id')
                    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('milvus_docs')
    op.drop_index(op.f('ix_docs_id'), table_name='docs')
    op.drop_table('docs')
    # ### end Alembic commands ###

================================================================================
–§–ê–ô–õ: package/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: package/celery/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: package/celery/tasks.py
================================================================================

from celery import Task
import requests

from internal.config.settings import settings

webhook_url = settings.TELEGRAM_WEBHOOK


class MyTaskWithSuccess(Task):
    # –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏
    def on_success(self, retval, task_id, args, kwargs):
        _, user_id, document = retval
        print(f"Document: {document}, User ID: {user_id}")
        result = requests.post(webhook_url, json={"file_url": f'https://cdn.student-space.ru/{document}',
                                                  "user_id": user_id})
        super().on_success(retval, task_id, args, kwargs)

    # –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ (–¥–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã –ø—Ä–∏–º–µ—Ä–∞)
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        print(f"Task {task_id} failed with exception: {exc}")
        super().on_failure(exc, task_id, args, kwargs, einfo)

================================================================================
–§–ê–ô–õ: package/celery/worker.py
================================================================================

import uuid
import asyncio
from io import BytesIO

from markdown_pdf import MarkdownPdf, Section
from celery import Celery

from internal.config import get_milvus_client, get_gpt_client, get_minio_client
from internal.config.settings import settings, buckets
from internal.dto.docs import DocsCreate, MilvusDocsRead
from internal.service.docs import DocsService, MilvusDocsService
from internal.service.utils import get_service
from package.celery.tasks import MyTaskWithSuccess
from package.pdf import PDFProcessor

celery = Celery(__name__, broker=str(settings.CELERY_BROKER_URL), backend=str(settings.CELERY_RESULT_BACKEND))

minio_client = get_minio_client()
chatgpt_client = get_gpt_client()
milvus_client = get_milvus_client()


def process_pdf_and_extract(file_stream: BytesIO, start_page: int = 0):
    """
    Process a PDF file and extract text.

    This function utilizes a PDF processing utility to extract text from a given
    PDF file stream. It initializes a PDFProcessor object with the provided file
    stream, processes the PDF starting from the specified page, and extracts the
    text content from all processed pages. The extracted text is returned as a
    single concatenated string with line breaks.

    Args:
        file_stream (BytesIO): A binary stream representing the PDF file.
        start_page (int): The page number to start processing the PDF from. Defaults
            to 0.

    Returns:
        str: The extracted text from the PDF, concatenated with line breaks.
    """
    pdf_processor = PDFProcessor(file_stream)
    pdf_processor.process_pdf(start_page=start_page, end_page=pdf_processor.pages)
    return '\n'.join(pdf_processor.extract())


def handle_embeddings_and_texts(chunks: list, collection_name: str, prompt_type: str):
    """
    Handles the embedding creation from chunks, searches for matching vectors in
    Milvus storage, and processes text data from the input chunks if no sufficient
    match is found.

    Combines the functionality of generating embeddings with the external API,
    querying the vector database for relevant matches, validating match thresholds,
    and generating fallback or additional results for unmatched embeddings and texts.

    Parameters:
        chunks (list): A list of input text chunks to process for embedding and text
        handling.

        collection_name (str): The name of the embedding collection in the Milvus
        database to perform the vector search.

        prompt_type (str): The type of the prompt to be used when generating embeddings.

    Returns:
        Tuple: A tuple containing the generated embedding, search results from the
        Milvus database, and optionally, a tuple of new embeddings and concatenated
        processed text if no sufficient match is found.
    """
    if prompt_type is not None:
        chatgpt_client.system_prompt = prompt_type
    embedding = chatgpt_client.create_embeddings(chunks)
    results = milvus_client.search_vectors(collection_name, query_vector=embedding, limit=1)
    if results and results[0]['distance'] >= 0.9:
        return embedding, results, None
    new_embeddings = [embedding]
    texts = ''.join(chatgpt_client.send_message(chunk) for chunk in chunks)
    return embedding, results, (new_embeddings, texts)


@celery.task(base=MyTaskWithSuccess, name='process_document')
def process_document(filename: str, bucket: str, user_id: str, prompt_type: str):
    """
    Asynchronous task for processing a document file stored in a MinIO bucket. The task includes
    retrieval of the file, processing it to extract text, preparing embeddings for the text chunks,
    and storing the final results in a Milvus database. Additionally, it generates a new PDF file
    from the processed text and uploads it back to a specified MinIO bucket.

    Args:
        filename (str): Name of the file to be processed from the MinIO bucket.
        bucket (str): Name of the MinIO bucket where the file is stored.
        user_id (str): ID of the user processing the document.
        prompt_type (str): Type of the prompt for the user to prompt.

    Returns:
        dict: A dictionary representing the result created in the Milvus database.

    Raises:
        KeyError: Raised in case of unexpected missing buckets during operations.
        StorageException: Raised on failure to interact with MinIO client.
        ProcessingException: Raised for any issues in text processing or PDF creation.
        DatabaseException: Raised for errors occurring during interactions with Milvus.
    """
    file, _ = minio_client.get_file_from_bucket(bucket_name=bucket, object_name=filename)
    file_stream = BytesIO(file)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF
    long_text = process_pdf_and_extract(file_stream)

    # –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
    chunks = chatgpt_client.split_text_into_chunks(long_text, chunk_size=chatgpt_client.max_tokens)

    # –†–∞–±–æ—Ç–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–∞–º–∏
    embedding, results, embeddings_and_texts = handle_embeddings_and_texts(
        chunks,
        settings.COLLECTION_NAME,
        prompt_type)

    if embeddings_and_texts is None:
        for milvus_object in results:
            result = asyncio.run(__get_docs_milvus(milvus_object['id']))
            if result is None:
                continue
            return result, user_id, result['docs']['s3_briefly']

    new_embeddings, texts = embeddings_and_texts
    ids = milvus_client.insert_vectors(settings.COLLECTION_NAME, new_embeddings)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ MinIO
    pdf = MarkdownPdf(toc_level=3)
    pdf.add_section(Section(texts, toc=False))
    pdf.writer.close()
    pdf.out_file.seek(0)
    object_name = f"{uuid.uuid4()}.pdf"
    new_bucket = buckets.get('pdf')
    minio_client.upload_file_to_bucket(file_io=pdf.out_file, bucket_name=new_bucket, object_name=object_name)
    result = asyncio.run(__create_docs_milvus(ids, object_name, new_bucket))
    return result, user_id, result['s3_briefly']


async def __create_docs_milvus(
        milvus_ids: list[int],
        doc_name: str,
        bucket: str,
):
    async with get_service(DocsService) as docs_service:
        s3_briefly = f"{bucket}/{doc_name}"
        dto_doc = DocsCreate(
            name=doc_name,
            s3_briefly=s3_briefly,
        )
        result = await docs_service.create_docs_and_milvus(dto_doc, milvus_ids)
        return result


async def __get_docs_milvus(milvus_id: int):
    async with get_service(MilvusDocsService) as milvus_docs_service:
        result = await milvus_docs_service.get_one_or_none(milvus_id)
        return MilvusDocsRead.model_validate(result).model_dump()

================================================================================
–§–ê–ô–õ: package/milvus/__init__.py
================================================================================

from .main import MilvusClient

================================================================================
–§–ê–ô–õ: package/milvus/main.py
================================================================================

import logging

from pymilvus import (
    Collection,
    CollectionSchema,
    DataType,
    FieldSchema,
    connections,
    has_collection,
)


class MilvusClient:
    def __init__(self, host: str = 'localhost', port: str = '19530'):
        """
        Initializes a new instance of MilvusClient.

        Args:
            host (str): The host address of the Milvus server.
            port (str): The port number of the Milvus server.
        """
        self.host = host
        self.port = port
        self.connection_alias = 'default'
        self._connect()

    def _connect(self):
        """
        Establish a connection to the Milvus server.
        """
        connections.connect(alias=self.connection_alias, host=self.host, port=self.port)

    def create_collection(self, collection_name: str, dim: int, metric_type: str = 'COSINE'):
        """
        Create a collection in Milvus if it does not already exist.

        Args:
            collection_name (str): The name of the collection.
            dim (int): The dimensionality of the vectors.
            metric_type (str): The distance metric type (COSINE, L2, etc.).
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
        if not has_collection(collection_name):
            fields = [
                FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),
                FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=dim),
            ]
            schema = CollectionSchema(fields, description=f'Collection for {collection_name}')
            collection = Collection(name=collection_name, schema=schema)

            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            index_params = {
                'index_type': 'HNSW',
                'metric_type': metric_type,
                'params': {'M': 32, 'efConstruction': 400},
            }
            collection.create_index(field_name='vector', index_params=index_params)
            logging.info(f'–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞.')
        else:
            logging.info(f'–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.')

    def insert_vectors(self, collection_name: str, vectors: list[list[float]]) -> list[int]:
        """
        Insert vectors into a collection with auto-incremented IDs.

        Args:
            collection_name (str): The name of the collection.
            vectors (list[list[float]]): List of vectors to insert.
        """
        collection = Collection(collection_name)

        mutation_result = collection.insert(vectors)

        generated_ids = mutation_result.primary_keys

        logging.info(f'Inserted {len(vectors)} vectors into collection {collection_name}')
        return generated_ids

    def search_vectors(self, collection_name: str, query_vector: list[list[float]], limit: int = 5):
        """
        Search for similar vectors in a collection.

        Args:
            collection_name (str): The name of the collection.
            query_vector: list((list[float])): The vector to search for.
            limit (int): The number of top results to return.

        Returns:
            list[dict]: List of search results with IDs and distances.
        """
        collection = Collection(collection_name)
        collection.load()
        search_params = {'metric_type': 'COSINE', 'params': {'ef': 50}}
        results = collection.search(
            data=query_vector,
            anns_field='vector',
            param=search_params,
            limit=limit,
            output_fields=['id'],
        )
        output = [
            {'id': hit.id, 'distance': hit.distance} for hits in results for hit in hits
        ]
        logging.info(f'Search completed. Found {len(output)} results.')
        return output

    def delete_vector(self, collection_name: str, vector_id: int):
        """
        Delete a vector from a collection by its ID.

        Args:
            collection_name (str): The name of the collection.
            vector_id (int): The ID of the vector to delete.
        """
        collection = Collection(collection_name)
        expr = f'id == {vector_id}'
        collection.delete(expr)
        logging.info(f'Vector with ID {vector_id} deleted from collection {collection_name}')

    def drop_collection(self, collection_name: str):
        """
        Drop a collection from Milvus.

        Args:
            collection_name (str): The name of the collection.
        """
        collection = Collection(collection_name)
        collection.drop()
        logging.info(f'Collection {collection_name} dropped.')

    def get_all_vectors(self, collection_name: str):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –∏—Ö ID –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏.

        Args:
            collection_name (str): –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏.

        Returns:
            list[dict]: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å –∏—Ö ID.
        """
        collection = Collection(collection_name)
        collection.load()

        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        results = collection.query(expr='id != 0', output_fields=['id', 'vector'], liimit=100)

        logging.info(f'–ü–æ–ª—É—á–µ–Ω–æ {len(results)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name}')
        return results

================================================================================
–§–ê–ô–õ: package/minio/__init__.py
================================================================================


================================================================================
–§–ê–ô–õ: package/minio/main.py
================================================================================

import logging
from urllib3 import PoolManager
from minio import Minio


class MinioClient(object):

    def __init__(self, endpoint: str, access_key: str, secret_key: str):
        """
        Initializes a new instance of a class with the necessary credentials and
        endpoint configuration to perform operations.

        Args:
            endpoint (AnyUrl): The base URL for the endpoint to connect to.
            access_key (str): The public key required for authentication.
            secret_key (str): The private key used for secure access.

        """
        self.__secret_key = secret_key
        self._access_key = access_key
        self.uri = endpoint
        self.__client: Minio | None = None
        self._http_client = PoolManager(
            num_pools=10,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–ª–æ–≤
            maxsize=10,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
            timeout=10.0  # –¢–∞–π–º–∞—É—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –æ–±—ä–µ–∫—Ç Timeout)
        )

    @property
    def connection(self) -> Minio:
        """
        Returns a Minio client connection. This property checks if the client
        is initialized, if not, it creates a new Minio client using the provided URI,
        access key, and secret key, and then returns the client. This ensures a
        consistent and efficient way to manage the Minio client connection.

        Attributes:
            __client (Minio): The Minio client used for connecting to the storage.
            uri (str): The URI of the Minio server.
            _access_key (str): The access key for authentication with the Minio server.
            __secret_key (str): The secret key for authentication with the Minio server.

        Returns:
            Minio: The Minio client connection.
        """
        if self.__client is None:
            self.__client = Minio(self.uri,
                                  access_key=self._access_key,
                                  secret_key=self.__secret_key,
                                  secure=False,
                                  http_client=self._http_client
                                  )
            logging.info(f'Set connection to minio by address: {self.uri} ')
        return self.__client

    def get_or_create_bucket(self, bucket_name: str) -> (bool, str):
        """
        Manages operations related to bucket creation and management in a storage
        service.

        Attributes:
            connection: Represents the connection to the storage service.
        """
        logging.info(f'Get or create bucket: {bucket_name}')
        bucket = self.connection.bucket_exists(bucket_name)
        if bucket is None:
            logging.info(f'Create bucket: {bucket_name}')
            self.connection.make_bucket(bucket_name=bucket_name)
        return bucket, bucket_name

    def delete_file_from_bucket(self, bucket_name: str, object_name: str) -> None:
        _, bucket = self.get_or_create_bucket(bucket_name)
        self.connection.remove_object(bucket_name, object_name)

    def upload_file_to_bucket(self, bucket_name: str, file_io, object_name: str) -> None:
        """
        Uploads a file from io format to a specified bucket in the storage service.

        Args:
            bucket_name (str): The name of the bucket where the file will be stored.
            file_io (IO): The file-like object to upload.
            object_name (str): The name of the object in the bucket.
        """
        _, bucket = self.get_or_create_bucket(bucket_name)
        self.connection.put_object(
            bucket_name=bucket,
            object_name=object_name,
            data=file_io,
            length=-1,  # Specify the file length, or for unknown length specify -1 for stream
            part_size=10 * 1024 * 1024  # You can adjust the part size
        )
        logging.info(f'Upload file: {object_name} to bucket: {bucket}')

    def get_file_from_bucket(self, bucket_name: str, object_name: str) -> (bytes, str):
        """
        Downloads a file from a specified bucket and returns its content and URL.

        Args:
            bucket_name (str): The name of the bucket from which to download the file.
            object_name (str): The name of the object to download.

        Returns:
            Tuple: A tuple containing the file content (as bytes) and the URL for accessing the file.
        """
        # Getting the object from the bucket
        response = self.connection.get_object(bucket_name, object_name)
        try:
            # Reading the data from the response
            file_data = response.read()
        finally:
            # Make sure to close the response to release the connection
            response.close()
            response.release_conn()

        # Constructing a URL for the object
        url = self.connection.presigned_get_object(bucket_name, object_name)

        logging.info(f'Get file: {object_name} to bucket: {bucket_name}')
        return file_data, url

================================================================================
–§–ê–ô–õ: package/openai/__init__.py
================================================================================

from .prompts import PromptManager
from .client import ChatGPTClient

================================================================================
–§–ê–ô–õ: package/openai/client.py
================================================================================

import logging
from typing import Any, List, Optional, Generator

import tiktoken
from langchain.schema import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from pydantic import SecretStr


class ChatGPTClient(object):
    def __init__(
            self,
            api_key: SecretStr,
            model_name: str = 'gpt-4o-mini',
            embeddings_model_name: str = 'text-embedding-ada-002',
            system_prompt: Optional[str] = None,
            mathematical_percent: Optional[int] = 20,
    ):
        """Initialize the configuration for interacting with OpenAI's GPT-4 and text.

        embedding models. It sets up the necessary components to communicate with the
        OpenAI API, including chat and embeddings model instances, tokenizers, and the
        system prompt if provided. The class handles token limit settings based on the
        specified models and manages initial chat history.

        Args:
            api_key: A secret string representing the OpenAI API key required for
                authentication.
            model_name: The name of the chat model to be used, defaulting to 'gpt-4'.
                Determines which model to use for chat operations.
            embeddings_model_name: The name of the embeddings model to be used,
                defaulting to 'text-embedding-ada-002'. It defines which model is to be
                utilized for handling text embeddings.
            system_prompt: An optional string for setting a system-level prompt
                message. If provided, it initializes the conversation context with this
                prompt.
            mathematical_percent: An optional integer defining a mathematical parameter,
                defaulting to 100. This parameter may be used for internal calculations
                or configurations.

        """
        self._api_key = api_key
        self.model_name = model_name
        self.math_p = mathematical_percent
        self.embeddings_model_name = embeddings_model_name
        self.chat_model = ChatOpenAI(
            openai_api_key=self._api_key,
            model_name=self.model_name,
        )
        self.embeddings_model = OpenAIEmbeddings(
            openai_api_key=self._api_key,
            model=self.embeddings_model_name,
        )
        self.chat_history = []

        # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã
        self.tokenizer = tiktoken.get_encoding('cl100k_base')
        self.embeddings_tokenizer = tiktoken.get_encoding('cl100k_base')

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
        self.system_prompt = system_prompt
        if self.system_prompt:
            system_message = SystemMessage(content=self.system_prompt)
            self.chat_history.append(system_message)

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–∏–º–∏—Ç–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–µ–π

        self.token = self.get_model_token_limit(self.model_name)
        self.max_tokens = self.token - int((self.token / 100) * self.math_p)
        self.embeddings_max_tokens = self.get_model_token_limit(self.embeddings_model_name)

    def get_model_token_limit(self, model_name: str) -> int:
        """Retrieve the token limit for a specified model.

        This function takes a model name as input and returns the token limit
        associated with that model. It uses a predefined dictionary to map
        model names to their respective token limits. If the provided model
        name is not found in the dictionary, a default token limit is
        returned.

        Args:
            model_name: The name of the model for which the token limit is
                requested.

        Returns:
            The token limit for the specified model. If the model is not
            found, a default value of 4096 is returned.
        """
        model_token_limits = {
            'gpt-3.5-turbo': 4096,
            'gpt-3.5-turbo-16k': 16384,
            'gpt-4': 8192,
            # 'gpt-4o-mini': 16384,
            'gpt-4o-mini': 2100,  # —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–∫–∞–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤.
            'gpt-4-32k': 32768,
            'text-embedding-ada-002': 8191,  # –õ–∏–º–∏—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        }
        return model_token_limits.get(model_name, 2000)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 4096, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞

    def create_embeddings(self, texts: List[str] | Generator) -> List[Any]:
        """Create embeddings for the provided texts.

        This method processes a list of texts by tokenizing each text and checking
        if the number of tokens is within the specified maximum tokens limit. If a
        text exceeds the token limi, it splits the text into smaller chunks that
        fit the limit. It then generates embeddings for all valid texts or chunks
        using the specified embeddings model.

        Args:
            texts (List[str]): A list of input texts to generate embeddings for.

        Returns:
            List[Any]: A list containing the embeddings of the valid texts.
        """
        valid_texts = []
        for text in texts:
            tokens = self.embeddings_tokenizer.encode(text)
            if len(tokens) <= self.embeddings_max_tokens:
                valid_texts.append(text)
            else:
                chunks = self.split_text_into_chunks(
                    text,
                    self.embeddings_max_tokens,
                    tokenizer=self.embeddings_tokenizer,
                )
                valid_texts.extend(chunks)
        logging.info('Create Embeddings.')
        return self.embeddings_model.embed_documents(valid_texts)

    def tokenize_text(self, text: str, tokenizer=None) -> List[int]:
        """Tokenize the input text using the specified tokenizer.

        If no tokenizer is provided, the default one is used. The function
        returns a list of token IDs that represent the text in a format
        suitable for processing by language models.

        Args:
            text (str): The text to be tokenized.
            tokenizer: The tokenizer instance to use for tokenization. If
                None, the default tokenizer of the class is used.

        Returns:
            List[int]: A list of integer token IDs representing the
            tokenized form of the input text.
        """
        if tokenizer is None:
            tokenizer = self.tokenizer
        tokens = tokenizer.encode(text)
        logging.info('Tokenize text.')
        return tokens

    def split_text_into_chunks(self, text: str, chunk_size: int, tokenizer=None) -> List[str]:  # noqa: WPS210
        """Split the provided text into chunks based on a specified chunk size.

        The text is tokenized using the provided tokenizer (or a default tokenizer),
        divided into segments of tokens, and then each segment is decoded back into a
        text chunk. This function is useful for handling large text by processing it in
        smaller manageable pieces.

        Args:
            text: The input text that needs to be chunked.
            chunk_size: The number of tokens each chunk should contain.
            tokenizer: An optional tokenizer to be used for tokenizing the text. If no
                tokenizer is provided, a default tokenizer is used.

        Returns:
            A list of strings where each string is a chunk of the original text.
        """
        if tokenizer is None:
            tokenizer = self.tokenizer
        tokens = self.tokenize_text(text, tokenizer)
        chunks = []
        for i in range(0, len(tokens), chunk_size):
            chunk_tokens = tokens[i:i + chunk_size]
            chunk_text = tokenizer.decode(chunk_tokens)
            chunks.append(chunk_text)
        logging.info('Split text to chunks.')
        return chunks

    def send_message(self, message: str) -> str:
        """Send a message to a chat model and receive a response.

        This function manages chat history by appending the human message and assistant
        response, and ensures that the token limit for the model is not
        exceeded before sending the message.

        Args:
            message (str): The message content to be sent to the chat model.

        Returns:
            str: The response content from the chat model.
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–¥–µ–ª–∏
        human_message = HumanMessage(content=message)
        new_message_tokens = len(self.tokenize_text(human_message.content))
        self.trim_chat_history(new_message_tokens)
        self.chat_history.append(human_message)
        assistant_message = self.chat_model.invoke(self.chat_history)
        self.chat_history.append(assistant_message)
        logging.info('Send message to OpenAI client.')
        return assistant_message.content

    def trim_chat_history(self, new_message_tokens_length):
        """Trim the chat history to ensure the total number of tokens does not exceed a predefined maximum.

        This function iterates through the chat history starting from the most recent
        message, adding messages to a trimmed history list until the token limit is reached.

        Args:
            new_message_tokens_length: The number of tokens in the new message
                to be considered alongside the existing chat history.
        """

        total_tokens = new_message_tokens_length
        trimmed_history = []
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        for message in reversed(self.chat_history):
            message_tokens = len(self.tokenize_text(message.content))
            if (total_tokens + message_tokens) <= self.max_tokens:
                trimmed_history.insert(0, message)  # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ
                total_tokens += message_tokens
            else:
                break

        # –≠—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –Ω–∞—á–∞–ª–µ
        if self.system_prompt:
            system_message = SystemMessage(content=self.system_prompt)
            trimmed_history.insert(0, system_message)

        self.chat_history = trimmed_history

    def reset_chat_history(self):
        """Manage the chat history including adding system prompts when necessary.

        Attributes:
            chat_history (list): A list that stores the chat history.
            system_prompt (str): A string representing the system prompt to be added
                to chat history, if it exists.
        """
        self.chat_history = []
        # –ü–æ–≤—Ç–æ—Ä–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if self.system_prompt:
            system_message = SystemMessage(content=self.system_prompt)
            self.chat_history.append(system_message)
        logging.info('Reset chat history.')

================================================================================
–§–ê–ô–õ: package/openai/prompts/__init__.py
================================================================================

from .manager import PromptManager

================================================================================
–§–ê–ô–õ: package/openai/prompts/manager.py
================================================================================

class PromptManager(object):
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º—Ç–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º–∏ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenAI API."""

    def __init__(self):
        self.prompts = {
            'retell': """–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
                –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Å—Ç–∞–≤–ª—è—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –º—ã—Å–ª—å, —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é.
                –ò–∑–ª–æ–∂–∏ –≤—Å–µ –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º. –û–±—ä–µ–º –¥–æ–ª–∂–µ–Ω —Å–æ–∫—Ä–∞—Ç–∏—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ 2 —Ä–∞–∑–∞ –æ—Ç –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ.""",
            'translate': '–¢—ã ‚Äî –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —è–∑—ã–∫.',
            'questions': '–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞–π–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞. –£–∫–∞–∂–∏ –∏—Ö –≤ —Å–ø–∏—Å–∫–µ, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–æ–Ω—Ç–µ–∫—Å—Ç.',
            'test': """
–¢—ã ‚Äî –≤—Å–µ–∑–Ω–∞—é—â–∏–π —á–µ–ª–æ–≤–µ–∫. –¢–µ–±–µ –Ω—É–∂–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –≤—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏.
–£–∫–∞–∑–∞–Ω–∏—è:
	1.	–í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ –ø–æ–Ω—è—Ç–∏—è.
	2.	–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –º–∞—Ç–µ—Ä–∏–∞–ª –ª–æ–≥–∏—á–µ—Å–∫–∏: –æ—Ç –±–∞–∑–æ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏–π –∫ —Å–ª–æ–∂–Ω—ã–º.
	3.	–°–∞–º–∏ –≤–æ–ø—Ä–æ—Å—ã –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.
–§–æ—Ä–º–∞—Ç:
    1.  –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã: –∫—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã, –æ —á–µ–º –ø–æ–π–¥–µ—Ç —Ä–µ—á—å.
	2.	–¢–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: –∫—Ä–∞—Ç–∫–∏–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏–π.
	3.	–û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏: —Ç–µ–∑–∏—Å—ã –∏ —Ñ–∞–∫—Ç—ã, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã.
	4.  –ü—Ä–∏–º–µ—Ä—ã —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á, –µ—Å–ª–∏ —Ç–∞–∫–æ–≤—ã–µ –∏–º–µ—é—Ç—Å—è.
–í–∞–∂–Ω–æ:
	‚Ä¢	–ò—Å–∫–ª—é—á–∏ –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è.
	‚Ä¢	–î–æ–±–∞–≤–ª—è–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, ‚Äú‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äù) —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞ –æ—Ç–≤–µ—Ç–∞, –∞ –Ω–µ –º–µ–∂–¥—É –µ–≥–æ —á–∞—Å—Ç—è–º–∏.
	‚Ä¢	–ü–∏—à–∏ —Å–∂–∞—Ç–æ –∏ —á–µ—Ç–∫–æ, —á—Ç–æ–±—ã –º–∞—Ç–µ—Ä–∏–∞–ª –±—ã–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º.
	‚Ä¢	–í—ã–¥–µ–ª—è–π —Ç–µ–∫—Å—Ç –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è. –ù–∞–ø—Ä–∏–º–µ—Ä –≤—ã–¥–µ–ª—è–π –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã, —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏.
	‚Ä¢	–ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ñ–æ—Ä–º—É–ª—ã, –ø–∏—à–∏ –∏—Ö —Ç–∞–∫, —á—Ç–æ–±—ã Markdown –∏—Ö —Ä–∞–∑–æ–±—Ä–∞–ª. –õ—É—á—à–µ –ø–∏—Å–∞—Ç—å —Ñ–æ—Ä–º—É–ª—ã —Ç–µ–∫—Å—Ç–æ–º –±–µ–∑ –≤—ã–¥–µ–ª–µ–Ω–∏–π –∏ –ø—Ä–æ—á–µ–≥–æ.
	‚Ä¢   –ù–µ –ø–∏—à–∏ –∑–∞–¥–∞—á–∏, –µ—Å–ª–∏ —Ç–∞–∫–æ–≤—ã—Ö –Ω–µ –∏–º–µ–µ—Ç—Å—è –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö.
	""",
        }

    def get_prompt(self, key: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–æ–º—Ç–∞ –ø–æ –∫–ª—é—á—É.

        Args:
            key (str): –ö–ª—é—á –ø—Ä–æ–º—Ç–∞.

        Returns:
            str: –¢–µ–∫—Å—Ç –ø—Ä–æ–º—Ç–∞.

        Raises:
            KeyError: –ï—Å–ª–∏ –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Å–ø–∏—Å–∫–µ –ø—Ä–æ–º—Ç–æ–≤.
        """
        if key not in self.prompts:
            print('ERRRORRRR')
            return self.prompts['retell']
        return self.prompts[key]

    def add_prompt(self, key: str, prompt: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø—Ä–æ–º—Ç.

        Args:
            key (str): –ö–ª—é—á –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º—Ç–∞.
            prompt (str): –¢–µ–∫—Å—Ç –ø—Ä–æ–º—Ç–∞.
        """
        self.prompts[key] = prompt

================================================================================
–§–ê–ô–õ: package/pagination.py
================================================================================

from dataclasses import dataclass
from functools import wraps
from typing import Any, Callable, Coroutine, Generic, TypeVar

from fastapi import Query
from pydantic.generics import GenericModel

T = TypeVar('T')


@dataclass
class Params(object):  # noqa: WPS110

    page: int = Query(1, ge=1, description='Page number')
    size: int = Query(50, ge=1, le=500, description='Page size')

    @property
    def limit(self) -> int:
        return self.size

    @property
    def offset(self) -> int:
        return self.size * (self.page - 1)


class Page(GenericModel, Generic[T]):
    items: list[T]  # noqa: WPS110

    total: int
    page: int
    size: int


PaginationEndpoint = Callable[[...], Coroutine[Any, Any, tuple[list[T], int]]]
PaginationWrapper = Callable[[...], Coroutine[Any, Any, Page[T]]]


def paginate(func: PaginationEndpoint) -> PaginationWrapper:
    @wraps(func)
    async def wrapper(*args, **kwargs) -> Page[T]:
        dto = kwargs.get('dto')
        items, total = await func(*args, **kwargs)  # noqa: WPS110
        return Page[T](items=items, total=total, page=dto.page, size=dto.size)

    return wrapper

================================================================================
–§–ê–ô–õ: package/pdf/__init__.py
================================================================================

from .main import PDFProcessor

================================================================================
–§–ê–ô–õ: package/pdf/main.py
================================================================================

from typing import Any, BinaryIO, Dict, List, Optional

import pdfplumber
import PyPDF2
from PyPDF2 import PdfFileWriter
from pdfminer.high_level import extract_pages
from pdfminer.layout import LTPage, LTRect, LTTextContainer

from .tools import extract_table, table_converter, text_extraction


class PDFProcessor:
    def __init__(self, pdf_file: BinaryIO):
        """
        Initialize the PDFProcessor class.

        Args:
            pdf_file (BinaryIO): An opened binary file object for the PDF.
        """
        self.pdf_file = pdf_file
        self.text_per_page: Dict[int, Dict[str, Any]] = {}
        self.pdf_reader = PyPDF2.PdfReader(self.pdf_file)

    @property
    def pages(self):
        return len(self.pdf_reader.pages)

    def process_pdf(self, start_page: int = 0, end_page: Optional[int] = None) -> None:
        """
        Processes a range of pages in the PDF, extracting text and formatting.

        Args:
            start_page (int): The starting page number (0-indexed).
            end_page (Optional[int]): The ending page number (0-indexed, exclusive). If None, processes until the last page.
        """
        num_pages = self.pages

        # –ï—Å–ª–∏ –∫–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∏–ª–∏ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –µ—ë –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        if end_page is None or end_page > num_pages:
            end_page = num_pages

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ä–µ–∑ —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞–∫ —Å–ø–∏—Å–æ–∫ PageObject
        pages_slice = self.pdf_reader.pages[start_page:end_page]

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Å—Ä–µ–∑–µ
        for page_num, page_text_obj in enumerate(pages_slice, start=start_page):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pdfminer –¥–ª—è –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            for page in extract_pages(self.pdf_file, page_numbers=[page_num]):
                page_content = self.process_page(page_num, page)
                self.text_per_page[page_num] = page_content

    def process_page(self, pagenum: int, page: LTPage) -> Dict[str, Any]:
        """
        Processes a single page of the PDF, extracting text, tables, and formatting.

        Args:
            pagenum (int): The page number.
            page (LTPage): The page object from pdfminer.

        Returns:
            Dict[str, Any]: A dictionary with extracted text, formatting, and other page content.
        """
        page_text: List[str] = []
        line_format: List[str] = []
        text_from_images: List[str] = []
        text_from_tables: List[str] = []
        page_content: List[str] = []

        table_num = 0
        first_element = True
        table_extraction_flag = False

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pdfplumber –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        with pdfplumber.open(self.pdf_file) as pdf:
            page_tables = pdf.pages[pagenum]
            tables = page_tables.find_tables()

        page_elements = [(element.y1, element) for element in page._objs]
        page_elements.sort(key=lambda a: a[0], reverse=True)
        for i, component in enumerate(page_elements):
            pos = component[0]
            element = component[1]

            if isinstance(element, LTTextContainer):
                if not table_extraction_flag:
                    line_text, format_per_line = text_extraction(element)
                    page_text.append(line_text)
                    line_format.append(format_per_line)
                    page_content.append(line_text)

            if isinstance(element, LTRect):
                if first_element and (table_num + 1) <= len(tables):
                    lower_side = page.bbox[3] - tables[table_num].bbox[3]
                    upper_side = element.y1
                    table = extract_table(self.pdf_file, pagenum, table_num)
                    table_string = table_converter(table)
                    text_from_tables.append(table_string)
                    page_content.append(table_string)
                    table_extraction_flag = True
                    first_element = False
                    page_text.append('table')
                    line_format.append('table')

                    if element.y0 >= lower_side and element.y1 <= upper_side:
                        pass
                elif i + 1 < len(page_elements) and not isinstance(page_elements[i + 1][1], LTRect):
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã—Ö–æ–¥ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Å–ø–∏—Å–∫–∞
                    table_extraction_flag = False
                    first_element = True
                    table_num += 1

        return {
            'text': page_text,
            'line_format': line_format,
            'text_from_images': text_from_images,
            'text_from_tables': text_from_tables,
            'page_content': page_content,
        }

    def extract(self):
        """
        Generator function that yields the extracted content for each page in the PDF, including text and tables.

        Yields:
            str: A formatted string for each page that includes the page key, text from tables,
                 and main text content, separated by spaces and followed by newlines for readability.

        Example:
            For each page in the PDF, this function will yield a formatted string in the following format:
                'Page_X <table_text_1> <table_text_2> ... <text_line_1> <text_line_2> ...'
        """
        for key, value in self.text_per_page.items():
            yield ' '.join(value['text_from_tables'] + value['text'])


"""
--- EXAMPLE USAGE ---
"""
### pip install pdfplumber PyPDF2 pdfminer.six - —ç—Ç–∏ –ª–∏–±—ã –ø–æ—Å—Ç–∞–≤—å

from pathlib import Path

pdf_path = Path("files/–•–æ–±–ª.pdf") # —Ç—É—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É

with pdf_path.open("rb") as f:
    processor = PDFProcessor(f)
    processor.process_pdf()

    for page_num, page_content in enumerate(processor.extract(), start=1):
        print(f"\n=== –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} ===")
        print(page_content)

================================================================================
–§–ê–ô–õ: package/pdf/tools/__init__.py
================================================================================

from .formatter import extract_table, table_converter, text_extraction

================================================================================
–§–ê–ô–õ: package/pdf/tools/formatter.py
================================================================================

from typing import List, Optional

import pdfplumber
from pdfminer.layout import (
    LTChar,
    LTTextBoxHorizontal,
    LTTextContainer,
)

TableType = List[List[Optional[str]]]


def text_extraction(element: LTTextBoxHorizontal) -> (str, list):
    """
    Function for extraction text from pdf page.
    Args:
        element: TextBox element from pdfminer library.

    Returns: Two value. Text in current page and all format text in page.
    """
    line_text = element.get_text()
    line_formats = []
    for text_line in element:
        if not isinstance(text_line, LTTextContainer):
            continue
        for character in text_line:
            if not isinstance(character, LTChar):
                continue
            line_formats.append(character.fontname)
            line_formats.append(character.size)
            line_formats.append(f'upright - {character.upright}')
            line_formats.append(f'adv - {character.adv}')

    return line_text, list(set(line_formats))


def extract_table(pdf_path: str, page_num: int, table_num: int) -> TableType:
    """
    Function for get text from tables from pdf document.
    Args:
        pdf_path: path to pdf file.
        page_num: num pdf page.
        table_num: num table in pdf document.

    Returns: Data of tables.

    """
    pdf = pdfplumber.open(pdf_path)
    table_page = pdf.pages[page_num]
    table = table_page.extract_tables()[table_num]
    return table


def table_converter(table: TableType) -> str:
    """
    Function for convert table view to text.
    Args:
        table: Table object (pandas table object)

    Returns: String view of table in pdf file.

    """
    table_string = ''
    for row_num in range(len(table)):
        row = table[row_num]
        cleaned_row = [
            item.replace('\n', ' ') if item is not None and '\n' in item else 'None' if item is None else item for item
            in row]
        table_string += ('|' + '|'.join(cleaned_row) + '|' + '\n')
    table_string = table_string[:-1]
    return table_string

================================================================================
–§–ê–ô–õ: requirements.txt
================================================================================

PyPDF2>=3.0.0
pdfminer.six>=20221105
pdfplumber>=0.9.0
aiohttp>=3.8.0
pydantic>=1.10.0
pydantic-settings>=1.3.0
openai>=0.27.8
pytesseract>=0.3.10
tiktoken>=0.5.0
langchain-openai>=0.2.0
markdown2>=2.4.10
pdfkit>=1.0.0
markdown-pdf>=0.11.0
minio>=7.1.8
pymilvus>=1.2.3
sqlalchemy>=2.0.21
fastapi>=0.103.0
alembic>=1.12.0
asyncpg>=0.29.0
greenlet>=2.1.4
uvicorn==0.32.1
python-multipart
celery==5.2.7
flower==1.2.0
redis
langchain
gunicorn
aiogram==3.17.0
flask==3.1.0

================================================================================
–§–ê–ô–õ: setup.cfg
================================================================================

[isort]
# Isort configuration:
line_length = 70
multi_line_output = 3
use_parentheses = true
include_trailing_comma = true
extend_skip = migrations/versions


[flake8]
# Base flake8 configuration:
format = wemake
doctests = true
show-source = true
statistics = false

# Plugins:
max-methods = 9
max-arguments = 10
min-name-length = 1
max-expressions = 15
max-line-length = 125
max-string-usages = 10
max-line-complexity = 20
max-attributes = 20

# Self settings:
i-control-code = false
extend-immutable-calls = Depends
nested-classes-whitelist = Meta, Params, Config

# Excluding some directories:
exclude =
    .git
    .venv
    venv
    .idea
    .vscode
    .mypy_cache
    __pycache__
    migrations
    main.py
    package/pdf/tools/formatter.py
    package/openai/prompts/*

# Violations:
ignore = D100, D101, D102, D103, D104, D105, D106, D107, N805, WPS114, WPS332, WPS354, WPS404, WPS432, WPS305, WPS462, WPS318
per-file-ignores =
    response*: WPS114
    settings*: WPS115
    __init__.py: WPS300, F401, F403, WPS347
    package/openai/__init__.py: WPS300, F401, F403, WPS347
    package/openai/prompts/__init__.py: WPS300, F401, F403, WPS347
    package/milvus/__init__.py: WPS300, F401, F403, WPS347
    service.py: WPS110, WPS125
    package/rabbitmq/rpc/routing.py: S101
    internal/dto/rule/filter/*: WPS102, WPS110, WPS201, WPS300, F401
    package/openai/*: D205, W391, RST301, RST201, D202

